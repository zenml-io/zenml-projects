{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Personalized AI with Flux.1 and Stable Diffusion Image to Video: A Step-by-Step Guide\n",
    "\n",
    "Hey there, AI enthusiasts! ğŸ‘‹ Ready to dive into the wild world of personalized AI models? Buckle up, because we're about to embark on an epic journey to create a system that can handle thousands of personalized Flux.1 model finetunings like it's no big deal. We'll be using the awesome power of DreamBooth and some nifty open-source tools like ZenML to make this magic happen.\n",
    "\n",
    "By the time you're done with this notebook, you'll be slinging personalized AI models like a pro. Whether you're a seasoned ML wizard or a curious newbie, this guide will give you the superpowers you need to bring these ideas to life in your own mad scientist projects. Let's get this party started! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up Our Environment\n",
    "\n",
    "First things first, let's get our environment ready for some serious AI action. We'll import all the necessary libraries and set up our configuration classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ZenML server\n",
    "!zenml connect --url <your-zenml-server-url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ZenML integrations\n",
    "!zenml stack set azure_temp_gpu\n",
    "!zenml integration install kubernetes azure -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to do this to get the docker daemon running\n",
    "import os\n",
    "\n",
    "# Add Docker to the PATH\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/Applications/Docker.app/Contents/Resources/bin/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inspect our dataset\n",
    "\n",
    "Now that we've got our environment set up, let's create a function to load our training data. This bad boy will help us grab all those juicy image paths we'll use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.client import Client\n",
    "from zenml.utils import io_utils\n",
    "\n",
    "images_path = \"az://demo-zenmlartifactstore/hamza-faces\"\n",
    "images_dir_path = \"/tmp/hamza-faces/\"\n",
    "_ = Client().active_stack.artifact_store.path\n",
    "\n",
    "io_utils.copy_dir(\n",
    "    destination_dir=images_dir_path,\n",
    "    source_dir=images_path,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e441ded4fd84726b2e55107ad566cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Displaying 10 of 201 images</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b34f19da644a1ba3d73580ab9412e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xae\\x00\\x00\\x00\\xa2\\x08\\x02\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_image_gallery(\n",
    "    images_dir_path, sample_size=10, thumbnail_size=(200, 200)\n",
    "):\n",
    "    # Get all image files from the directory\n",
    "    image_files = [\n",
    "        f\n",
    "        for f in os.listdir(images_dir_path)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ]\n",
    "\n",
    "    # Sample the images\n",
    "    sampled_files = random.sample(\n",
    "        image_files, min(sample_size, len(image_files))\n",
    "    )\n",
    "\n",
    "    # Create thumbnail widgets\n",
    "    thumbnails = [\n",
    "        widgets.Image(\n",
    "            value=open(os.path.join(images_dir_path, img), \"rb\").read(),\n",
    "            format=img.split(\".\")[-1],\n",
    "            layout=widgets.Layout(\n",
    "                width=f\"{thumbnail_size[0]}px\",\n",
    "                height=f\"{thumbnail_size[1]}px\",\n",
    "                margin=\"5px\",\n",
    "            ),\n",
    "        )\n",
    "        for img in sampled_files\n",
    "    ]\n",
    "\n",
    "    # Create a grid of thumbnails\n",
    "    thumbnail_grid = widgets.GridBox(\n",
    "        thumbnails,\n",
    "        layout=widgets.Layout(\n",
    "            grid_template_columns=\"repeat(auto-fill, minmax(200px, 1fr))\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Display the gallery\n",
    "    display(\n",
    "        widgets.HTML(\n",
    "            f\"<h3>Displaying {len(sampled_files)} of {len(image_files)} images</h3>\"\n",
    "        )\n",
    "    )\n",
    "    display(thumbnail_grid)\n",
    "\n",
    "\n",
    "# Usage\n",
    "display_image_gallery(images_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training Our Model Like a Boss\n",
    "\n",
    "Alright, now we're getting to the good stuff. Let's set up our model training step. This is where the magic happens, folks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from train_dreambooth_lora_flux import main as dreambooth_main\n",
    "from zenml import step\n",
    "from zenml.client import Client\n",
    "from zenml.integrations.huggingface.steps import run_with_accelerate\n",
    "from zenml.utils import io_utils\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@run_with_accelerate(\n",
    "    num_processes=1, multi_gpu=False, mixed_precision=\"bf16\"\n",
    ")  # Adjust num_processes as needed\n",
    "@step\n",
    "def train_model(\n",
    "    images_path: str,\n",
    "    instance_name: str,\n",
    "    class_name: str,\n",
    "    model_name: str,\n",
    "    hf_repo_suffix: str,\n",
    "    prefix: str,\n",
    "    resolution: int,\n",
    "    train_batch_size: int,\n",
    "    rank: int,\n",
    "    gradient_accumulation_steps: int,\n",
    "    learning_rate: float,\n",
    "    lr_scheduler: str,\n",
    "    lr_warmup_steps: int,\n",
    "    max_train_steps: int,\n",
    "    push_to_hub: bool,\n",
    "    checkpointing_steps: int,\n",
    "    seed: int,\n",
    ") -> None:\n",
    "\n",
    "    images_dir_path = \"/tmp/hamza-faces/\"\n",
    "    _ = Client().active_stack.artifact_store.path\n",
    "\n",
    "    io_utils.copy_dir(\n",
    "        destination_dir=images_dir_path,\n",
    "        source_dir=images_path,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    instance_phrase = f\"{instance_name} the {class_name}\"\n",
    "    instance_prompt = f\"{prefix} {instance_phrase}\".strip()\n",
    "\n",
    "    # Create an ArgumentParser-like object to mimic the args in the original script\n",
    "    class Args:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.mixed_precision = kwargs.get(\"mixed_precision\", \"bf16\")\n",
    "            self.pretrained_model_name_or_path = kwargs.get(\n",
    "                \"pretrained_model_name_or_path\"\n",
    "            )\n",
    "            self.revision = kwargs.get(\"revision\", None)\n",
    "            self.variant = kwargs.get(\"variant\", None)\n",
    "            self.dataset_name = kwargs.get(\"dataset_name\", None)\n",
    "            self.dataset_config_name = kwargs.get(\"dataset_config_name\", None)\n",
    "            self.instance_data_dir = kwargs.get(\"instance_data_dir\")\n",
    "            self.cache_dir = kwargs.get(\"cache_dir\", None)\n",
    "            self.image_column = kwargs.get(\"image_column\", \"image\")\n",
    "            self.caption_column = kwargs.get(\"caption_column\", None)\n",
    "            self.repeats = kwargs.get(\"repeats\", 1)\n",
    "            self.class_data_dir = kwargs.get(\"class_data_dir\", None)\n",
    "            self.output_dir = kwargs.get(\"output_dir\")\n",
    "            self.instance_prompt = kwargs.get(\"instance_prompt\")\n",
    "            self.class_prompt = kwargs.get(\"class_prompt\", None)\n",
    "            self.max_sequence_length = kwargs.get(\"max_sequence_length\", 512)\n",
    "            self.validation_prompt = kwargs.get(\"validation_prompt\", None)\n",
    "            self.num_validation_images = kwargs.get(\"num_validation_images\", 4)\n",
    "            self.validation_epochs = kwargs.get(\"validation_epochs\", 50)\n",
    "            self.rank = kwargs.get(\"rank\", 4)\n",
    "            self.with_prior_preservation = kwargs.get(\n",
    "                \"with_prior_preservation\", False\n",
    "            )\n",
    "            self.prior_loss_weight = kwargs.get(\"prior_loss_weight\", 1.0)\n",
    "            self.num_class_images = kwargs.get(\"num_class_images\", 100)\n",
    "            self.seed = kwargs.get(\"seed\", None)\n",
    "            self.resolution = kwargs.get(\"resolution\", 512)\n",
    "            self.center_crop = kwargs.get(\"center_crop\", False)\n",
    "            self.random_flip = kwargs.get(\"random_flip\", False)\n",
    "            self.train_text_encoder = kwargs.get(\"train_text_encoder\", False)\n",
    "            self.train_batch_size = kwargs.get(\"train_batch_size\", 4)\n",
    "            self.sample_batch_size = kwargs.get(\"sample_batch_size\", 4)\n",
    "            self.num_train_epochs = kwargs.get(\"num_train_epochs\", 1)\n",
    "            self.max_train_steps = kwargs.get(\"max_train_steps\", None)\n",
    "            self.checkpointing_steps = kwargs.get(\"checkpointing_steps\", 500)\n",
    "            self.checkpoints_total_limit = kwargs.get(\n",
    "                \"checkpoints_total_limit\", None\n",
    "            )\n",
    "            self.resume_from_checkpoint = kwargs.get(\n",
    "                \"resume_from_checkpoint\", None\n",
    "            )\n",
    "            self.gradient_accumulation_steps = kwargs.get(\n",
    "                \"gradient_accumulation_steps\", 1\n",
    "            )\n",
    "            self.gradient_checkpointing = kwargs.get(\n",
    "                \"gradient_checkpointing\", False\n",
    "            )\n",
    "            self.learning_rate = kwargs.get(\"learning_rate\", 1e-4)\n",
    "            self.guidance_scale = kwargs.get(\"guidance_scale\", 3.5)\n",
    "            self.text_encoder_lr = kwargs.get(\"text_encoder_lr\", 5e-6)\n",
    "            self.scale_lr = kwargs.get(\"scale_lr\", False)\n",
    "            self.lr_scheduler = kwargs.get(\"lr_scheduler\", \"constant\")\n",
    "            self.lr_warmup_steps = kwargs.get(\"lr_warmup_steps\", 500)\n",
    "            self.lr_num_cycles = kwargs.get(\"lr_num_cycles\", 1)\n",
    "            self.lr_power = kwargs.get(\"lr_power\", 1.0)\n",
    "            self.dataloader_num_workers = kwargs.get(\n",
    "                \"dataloader_num_workers\", 0\n",
    "            )\n",
    "            self.weighting_scheme = kwargs.get(\"weighting_scheme\", \"none\")\n",
    "            self.logit_mean = kwargs.get(\"logit_mean\", 0.0)\n",
    "            self.logit_std = kwargs.get(\"logit_std\", 1.0)\n",
    "            self.mode_scale = kwargs.get(\"mode_scale\", 1.29)\n",
    "            self.optimizer = kwargs.get(\"optimizer\", \"AdamW\")\n",
    "            self.use_8bit_adam = kwargs.get(\"use_8bit_adam\", False)\n",
    "            self.adam_beta1 = kwargs.get(\"adam_beta1\", 0.9)\n",
    "            self.adam_beta2 = kwargs.get(\"adam_beta2\", 0.999)\n",
    "            self.prodigy_beta3 = kwargs.get(\"prodigy_beta3\", None)\n",
    "            self.prodigy_decouple = kwargs.get(\"prodigy_decouple\", True)\n",
    "            self.adam_weight_decay = kwargs.get(\"adam_weight_decay\", 1e-04)\n",
    "            self.adam_weight_decay_text_encoder = kwargs.get(\n",
    "                \"adam_weight_decay_text_encoder\", 1e-03\n",
    "            )\n",
    "            self.adam_epsilon = kwargs.get(\"adam_epsilon\", 1e-08)\n",
    "            self.prodigy_use_bias_correction = kwargs.get(\n",
    "                \"prodigy_use_bias_correction\", True\n",
    "            )\n",
    "            self.prodigy_safeguard_warmup = kwargs.get(\n",
    "                \"prodigy_safeguard_warmup\", True\n",
    "            )\n",
    "            self.max_grad_norm = kwargs.get(\"max_grad_norm\", 1.0)\n",
    "            self.push_to_hub = kwargs.get(\"push_to_hub\", False)\n",
    "            self.hub_token = kwargs.get(\"hub_token\", None)\n",
    "            self.hub_model_id = kwargs.get(\"hub_model_id\", None)\n",
    "            self.logging_dir = kwargs.get(\"logging_dir\", \"logs\")\n",
    "            self.allow_tf32 = kwargs.get(\"allow_tf32\", False)\n",
    "            self.report_to = kwargs.get(\"report_to\", \"tensorboard\")\n",
    "            self.local_rank = kwargs.get(\"local_rank\", -1)\n",
    "            self.prior_generation_precision = kwargs.get(\n",
    "                \"prior_generation_precision\", None\n",
    "            )\n",
    "\n",
    "    # Usage example:\n",
    "    args = Args(\n",
    "        mixed_precision=\"bf16\",\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        instance_data_dir=images_dir_path,\n",
    "        output_dir=hf_repo_suffix,\n",
    "        instance_prompt=instance_prompt,\n",
    "        resolution=resolution,\n",
    "        train_batch_size=train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        rank=rank,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        lr_warmup_steps=lr_warmup_steps,\n",
    "        max_train_steps=max_train_steps,\n",
    "        checkpointing_steps=checkpointing_steps,\n",
    "        seed=seed,\n",
    "        push_to_hub=push_to_hub if push_to_hub else False,\n",
    "    )\n",
    "\n",
    "    # Run the main function with the created args\n",
    "    print(\"Launching dreambooth training script\")\n",
    "    dreambooth_main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Batch Inference - Let's See What We've Created!\n",
    "\n",
    "Now that we've trained our model, it's time to put it to the test. Let's set up a batch inference step to generate some cool images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from PIL import Image as PILImage\n",
    "from zenml import step\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "@step\n",
    "def batch_inference(\n",
    "    hf_username: str,\n",
    "    hf_repo_suffix: str,\n",
    "    instance_name: str,\n",
    "    class_name: str,\n",
    ") -> PILImage.Image:\n",
    "    model_path = f\"{hf_username}/{hf_repo_suffix}\"\n",
    "    pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "        \"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16\n",
    "    ).to(\"cuda\")\n",
    "    pipe.load_lora_weights(\n",
    "        model_path, weight_name=\"pytorch_lora_weights.safetensors\"\n",
    "    )\n",
    "\n",
    "    instance_phrase = f\"{instance_name} the {class_name}\"\n",
    "    prompts = [\n",
    "        f\"A portrait photo of {instance_phrase} in a Superman pose\",\n",
    "        f\"A portrait photo of {instance_phrase} flying like Superman\",\n",
    "        f\"A portrait photo of {instance_phrase} standing like Superman\",\n",
    "        f\"A portrait photo of {instance_phrase} as a football player in an action pose\",\n",
    "        f\"A portrait photo of {instance_phrase} as a firefighter in a heroic stance\",\n",
    "        f\"A portrait photo of {instance_phrase} in a spacesuit in space\",\n",
    "        f\"A portrait photo of {instance_phrase} on the Moon\",\n",
    "        f\"A portrait photo of {instance_phrase} as an astronaut working on a satellite\",\n",
    "        f\"A portrait photo of {instance_phrase} as an astronaut looking out a spacecraft window\",\n",
    "        f\"A portrait photo of {instance_phrase} as an astronaut on a spacewalk\",\n",
    "        f\"A portrait photo of {instance_phrase} in a heroic Superman pose\",\n",
    "        f\"A portrait photo of {instance_phrase} as an astronaut on Mars\",\n",
    "        f\"A portrait photo of {instance_phrase} flying like Superman\",\n",
    "        f\"A portrait photo of {instance_phrase} as an astronaut floating in zero gravity\",\n",
    "        f\"A portrait photo of {instance_phrase} as a superhero in a powerful stance\",\n",
    "    ]\n",
    "\n",
    "    images = pipe(\n",
    "        prompt=prompts,\n",
    "        num_inference_steps=35,\n",
    "        guidance_scale=8.5,\n",
    "        height=256,\n",
    "        width=256,\n",
    "    ).images\n",
    "\n",
    "    width, height = images[0].size\n",
    "    rows, cols = 3, 5\n",
    "    gallery_img = PILImage.new(\"RGB\", (width * cols, height * rows))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        gallery_img.paste(image, ((i % cols) * width, (i // cols) * height))\n",
    "\n",
    "    return gallery_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: From Still to Motion - Let's Make Some Video Magic!\n",
    "\n",
    "Why stop at images when we can create videos? Let's add a step to turn our generated image into a short video clip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import Annotated, Tuple, List\n",
    "\n",
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image, StableVideoDiffusionPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "from PIL import Image as PILImage\n",
    "from zenml import step\n",
    "from zenml.types import HTMLString\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "def get_optimal_size(\n",
    "    image: PILImage.Image, max_size: int = 1024\n",
    ") -> Tuple[int, int]:\n",
    "    width, height = image.size\n",
    "    aspect_ratio = width / height\n",
    "    if width > height:\n",
    "        new_width = min(width, max_size)\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        new_height = min(height, max_size)\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    return (new_width, new_height)\n",
    "\n",
    "\n",
    "@step\n",
    "def image_to_video(\n",
    "    hf_username: str,\n",
    "    hf_repo_suffix: str,\n",
    "    instance_name: str,\n",
    ") -> Tuple[\n",
    "    Annotated[List[PILImage.Image], \"generated_images\"],\n",
    "    Annotated[List[bytes], \"video_data_list\"],\n",
    "    Annotated[HTMLString, \"video_html\"],\n",
    "]:\n",
    "\n",
    "    model_path = f\"{hf_username}/{hf_repo_suffix}\"\n",
    "    pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "        \"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16\n",
    "    ).to(\"cuda\")\n",
    "    pipe.load_lora_weights(\n",
    "        model_path, weight_name=\"pytorch_lora_weights.safetensors\"\n",
    "    )\n",
    "\n",
    "    instance_phrase = f\"{instance_name} the man\"\n",
    "    prompts = [\n",
    "        f\"A portrait photo of {instance_phrase} in a Superman pose\",\n",
    "        f\"A portrait photo of {instance_phrase} flying like Superman\",\n",
    "        f\"A portrait photo of {instance_phrase} standing like Superman\",\n",
    "        f\"A portrait photo of {instance_phrase} as a football player in an action pose\",\n",
    "        f\"A portrait photo of {instance_phrase} as a firefighter in a heroic stance\",\n",
    "        f\"A portrait photo of {instance_phrase} in a spacesuit in space\",\n",
    "        f\"A portrait photo of {instance_phrase} on the Moon\",\n",
    "    ]\n",
    "\n",
    "    images = pipe(\n",
    "        prompt=prompts,\n",
    "        num_inference_steps=40,\n",
    "        guidance_scale=8.5,\n",
    "        height=512,\n",
    "        width=512,\n",
    "    ).images\n",
    "\n",
    "    video_pipeline = StableVideoDiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-video-diffusion-img2vid-xt\",\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "    )\n",
    "    video_pipeline.enable_model_cpu_offload()\n",
    "\n",
    "    video_data_list = []\n",
    "    for i, image in enumerate(images):\n",
    "        frames = video_pipeline(\n",
    "            image,\n",
    "            num_inference_steps=80,\n",
    "            generator=torch.manual_seed(77),\n",
    "            height=512,\n",
    "            width=512,\n",
    "        ).frames[0]\n",
    "\n",
    "        output_file = f\"generated_video_{i}.mp4\"\n",
    "        export_to_video(frames, output_file, fps=5)\n",
    "\n",
    "        with open(output_file, \"rb\") as file:\n",
    "            video_data = file.read()\n",
    "            video_data_list.append(video_data)\n",
    "\n",
    "    html_visualization_str = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div style=\"display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; padding: 0;\">\n",
    "    \"\"\"\n",
    "    for i, video_data in enumerate(video_data_list):\n",
    "        html_visualization_str += f\"\"\"\n",
    "            <div style=\"margin-bottom: 20px;\">\n",
    "                <video width=\"512\" height=\"512\" controls autoplay loop>\n",
    "                    <source src=\"data:video/mp4;base64,{base64.b64encode(video_data).decode()}\" type=\"video/mp4\">\n",
    "                    Your browser does not support the video tag.\n",
    "                </video>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    html_visualization_str += \"\"\"\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return (images, video_data_list, HTMLString(html_visualization_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Putting It All Together - Our Dreambooth Pipeline\n",
    "\n",
    "Now for the grand finale - let's string all these awesome steps together into one epic pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dreambooth pipeline assembled and ready for action! ğŸš€\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Dreambooth pipeline assembled and ready for action! ğŸš€\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "from zenml import pipeline\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def dreambooth_pipeline(\n",
    "    instance_example_dir: str = \"az://demo-zenmlartifactstore/hamza-faces\",\n",
    "    instance_name: str = \"sks htahir1\",\n",
    "    class_name: str = \"man\",\n",
    "    model_name: str = \"black-forest-labs/FLUX.1-dev\",\n",
    "    hf_username: str = \"strickvl\",\n",
    "    hf_repo_suffix: str = \"flux-dreambooth-hamza\",\n",
    "    prefix: str = \"A portrait photo of\",\n",
    "    resolution: int = 512,\n",
    "    train_batch_size: int = 1,\n",
    "    rank: int = 32,\n",
    "    gradient_accumulation_steps: int = 1,\n",
    "    learning_rate: float = 0.0002,\n",
    "    lr_scheduler: str = \"constant\",\n",
    "    lr_warmup_steps: int = 0,\n",
    "    max_train_steps: int = 1300,\n",
    "    push_to_hub: bool = True,\n",
    "    checkpointing_steps: int = 1000,\n",
    "    seed: int = 117,\n",
    "):\n",
    "    train_model(\n",
    "        instance_example_dir,\n",
    "        instance_name=instance_name,\n",
    "        class_name=class_name,\n",
    "        model_name=model_name,\n",
    "        hf_repo_suffix=hf_repo_suffix,\n",
    "        prefix=prefix,\n",
    "        resolution=resolution,\n",
    "        train_batch_size=train_batch_size,\n",
    "        rank=rank,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        lr_warmup_steps=lr_warmup_steps,\n",
    "        max_train_steps=max_train_steps,\n",
    "        push_to_hub=push_to_hub,\n",
    "        checkpointing_steps=checkpointing_steps,\n",
    "        seed=seed,\n",
    "    )\n",
    "    batch_inference(\n",
    "        hf_username,\n",
    "        hf_repo_suffix,\n",
    "        instance_name,\n",
    "        class_name,\n",
    "        after=\"train_model\",\n",
    "    )\n",
    "    image_to_video(\n",
    "        hf_username, hf_repo_suffix, instance_name, after=\"batch_inference\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Dreambooth pipeline assembled and ready for action! ğŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Launch the Pipeline and Watch the Magic Happen!\n",
    "\n",
    "Alright, folks, this is it - the moment of truth! Let's fire up our pipeline and see this baby in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mdreambooth_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUploading notebook code...\u001b[0m\n",
      "\u001b[1;35mUpload finished.\u001b[0m\n",
      "\u001b[1;35mReusing existing build \u001b[0m\u001b[1;36me100d938-3463-400f-a4a2-07ef891964b6\u001b[1;35m for stack \u001b[0m\u001b[1;36mazure_temp_gpu\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mArchiving pipeline code...\u001b[0m\n",
      "\u001b[1;35mUploading code to \u001b[0m\u001b[1;36maz://demo-zenmlartifactstore/code_uploads/e84ae2456e57b3d805d357562797d9d10c097702.tar.gz\u001b[1;35m (Size: 1.87 MiB).\u001b[0m\n",
      "\u001b[1;35mCode upload finished.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing a build:\u001b[0m\n",
      "\u001b[1;35m Image(s): demozenmlcontainerregistry.azurecr.io/zenml@sha256:c996d64b7caac50cd9215f7ce068cf3b308d8e764ec67ce99ef6d0bc14561926, demozenmlcontainerregistry.azurecr.io/zenml@sha256:c996d64b7caac50cd9215f7ce068cf3b308d8e764ec67ce99ef6d0bc14561926, demozenmlcontainerregistry.azurecr.io/zenml@sha256:c996d64b7caac50cd9215f7ce068cf3b308d8e764ec67ce99ef6d0bc14561926\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mazure_temp_gpu\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mrunners-azure-k8s\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36maz_store\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  container_registry: \u001b[0m\u001b[1;36maz_registry\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL for Pipeline Run: \u001b[0m\u001b[34mhttps://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/00616f46-8445-4a2f-a9d0-b4bf3d84642e\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mWaiting for Kubernetes orchestrator pod...\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mKubernetes orchestrator pod started.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mWaiting for pod of step \u001b[0m\u001b[1;36mtrain_model\u001b[1;35m to start...\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m/opt/conda/lib/python3.10/runpy.py:126: RuntimeWarning: 'zenml.entrypoints.entrypoint' found in sys.modules after import of package 'zenml.entrypoints', but prior to execution of 'zenml.entrypoints.entrypoint'; this may result in unpredictable behaviour\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  warn(RuntimeWarning(msg))\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mDownloading code from artifact store path \u001b[0m\u001b[1;36maz://demo-zenmlartifactstore/code_uploads/e84ae2456e57b3d805d357562797d9d10c097702.tar.gz\u001b[1;35m.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[33mCould not import AWS service connector: No module named 'boto3'.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[33mCould not import GCP service connector: cannot import name 'artifactregistry_v1' from 'google.cloud' (unknown location).\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mCode download finished.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mDownloading notebook cell content to load \u001b[0m\u001b[1;36m__main__.train_model\u001b[1;35m.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mCaching \u001b[0m\u001b[1;36menabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mtrain_model\u001b[1;35m.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mNew model version \u001b[0m\u001b[1;36m2\u001b[1;35m was created.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mDashboard URL for created Model Version \u001b[0m\u001b[1;36mflux_personalized_model::2\u001b[1;35m:\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[34m\u001b[0m\u001b[34m\u001b[0m\u001b[34mhttps://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/model-versions/d38ec69b-6378-46f3-b0b7-ac52016b710d\u001b[1;35m\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mStep \u001b[0m\u001b[1;36mtrain_model\u001b[1;35m has started.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[33mThe following values were not passed to \u001b[0m\u001b[1;36maccelerate launch\u001b[33m and had defaults used instead:\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\t\u001b[0m\u001b[1;36m--num_machines\u001b[33m was set to a value of \u001b[0m\u001b[1;36m1\u001b[33m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\t\u001b[0m\u001b[1;36m--dynamo_backend\u001b[33m was set to a value of \u001b[0m\u001b[1;36m'no'\u001b[33m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mTo avoid this warning pass in values for each of the problematic parameters or run \u001b[0m\u001b[1;36maccelerate config\u001b[33m.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[33mCould not import AWS service connector: No module named 'boto3'.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[33mCould not import GCP service connector: cannot import name 'artifactregistry_v1' from 'google.cloud' (unknown location).\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mLaunching dreambooth training script\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[1;35mDistributed environment: NO\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mNum processes: 1\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mProcess index: 0\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mLocal process index: 0\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mDevice: cuda\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mMixed precision type: bf16\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ in hf_raise_for_status                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   301 â”‚   </Tip>                                                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   302 â”‚   \"\"\"                                                                â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   303 â”‚   try:                                                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 304 â”‚   â”‚   response.raise_for_status()                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   305 â”‚   except HTTPError as e:                                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   306 â”‚   â”‚   error_code = response.headers.get(\"X-Error-Code\")              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   307 â”‚   â”‚   error_message = response.headers.get(\"X-Error-Message\")        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/requests/models.py:1024 in           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ raise_for_status                                                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1021 â”‚   â”‚   â”‚   )                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1022 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1023 â”‚   â”‚   if http_error_msg:                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1024 â”‚   â”‚   â”‚   raise HTTPError(http_error_msg, response=self)            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1025 â”‚                                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1026 â”‚   def close(self):                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1027 â”‚   â”‚   \"\"\"Releases the connection back to the pool. Once this method â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mHTTPError: 401 Client Error: Unauthorized for url: \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[34m\u001b[0m\u001b[34mhttps://huggingface.co/api/repos/create\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mThe above exception was the direct cause of the following exception:\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /app/code/FZZyFTUsKcOBYSnEBrsg.py:18 in <module>                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   15 â”‚   from accelerate import Accelerator                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   16 â”‚   import cloudpickle as pickle                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   17 â”‚   accelerator = Accelerator()                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 18 â”‚   ret = func(standalone_mode=False)                                   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   19 â”‚   if accelerator.is_main_process:                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   20 â”‚   â”‚   pickle.dump(ret, open(r\"/app/code/FZZyFTUsKcOBYSnEBrsg.out\", \"w â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   21                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/click/core.py:1130 in __call__       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1127 â”‚                                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1128 â”‚   def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Any:       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1129 â”‚   â”‚   \"\"\"Alias for :meth:\u001b[0m\u001b[1;36mmain\u001b[1;35m.\"\"\"                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1130 â”‚   â”‚   return self.main(*args, **kwargs)                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1131                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1132                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1133 class Command(BaseCommand):                                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/click/core.py:1055 in main           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1052 â”‚   â”‚   try:                                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1053 â”‚   â”‚   â”‚   try:                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1054 â”‚   â”‚   â”‚   â”‚   with self.make_context(prog_name, args, **extra) as c â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1055 â”‚   â”‚   â”‚   â”‚   â”‚   rv = self.invoke(ctx)                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1056 â”‚   â”‚   â”‚   â”‚   â”‚   if not standalone_mode:                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1057 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   return rv                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1058 â”‚   â”‚   â”‚   â”‚   â”‚   # it's not safe to \u001b[0m\u001b[1;36mctx.exit(rv)\u001b[1;35m here!           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/click/core.py:1404 in invoke         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1401 â”‚   â”‚   â”‚   echo(style(message, fg=\"red\"), err=True)                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1402 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1403 â”‚   â”‚   if self.callback is not None:                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1404 â”‚   â”‚   â”‚   return ctx.invoke(self.callback, **ctx.params)            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1405 â”‚                                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1406 â”‚   def shell_complete(self, ctx: Context, incomplete: str) -> t.List â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1407 â”‚   â”‚   \"\"\"Return a list of completions for the incomplete value. Loo â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/click/core.py:760 in invoke          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    757 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    758 â”‚   â”‚   with augment_usage_errors(__self):                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    759 â”‚   â”‚   â”‚   with ctx:                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â±  760 â”‚   â”‚   â”‚   â”‚   return __callback(*args, **kwargs)                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    761 â”‚                                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    762 â”‚   def forward(                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    763 â”‚   â”‚   __self, __cmd: \"Command\", *args: t.Any, **kwargs: t.Any  # no â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /tmp/tmpa4r19dec/extracted_notebook_code_6a62b738d958422f6d8b9b20159ca9e3003 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ e6003.py:166 in train_model                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   163 â”‚                                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   164 â”‚   # Run the main function with the created args                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   165 â”‚   print(\"Launching dreambooth training script\")                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 166 â”‚   dreambooth_main(args)                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   167                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /app/code/train_dreambooth_lora_flux.py:1287 in main                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1284 â”‚   â”‚   â”‚   os.makedirs(args.output_dir, exist_ok=True)               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1285 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1286 â”‚   â”‚   if args.push_to_hub:                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1287 â”‚   â”‚   â”‚   repo_id = create_repo(                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1288 â”‚   â”‚   â”‚   â”‚   repo_id=args.hub_model_id or Path(args.output_dir).na â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1289 â”‚   â”‚   â”‚   â”‚   exist_ok=True,                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1290 â”‚   â”‚   â”‚   ).repo_id                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ :114 in _inner_fn                                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   111 â”‚   â”‚   if check_use_auth_token:                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   112 â”‚   â”‚   â”‚   kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__na â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   113 â”‚   â”‚                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 114 â”‚   â”‚   return fn(*args, **kwargs)                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   115 â”‚                                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   116 â”‚   return _inner_fn  # type: ignore                                   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   117                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3363 in    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ create_repo                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3360 â”‚   â”‚   â”‚   break                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3361 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3362 â”‚   â”‚   try:                                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 3363 â”‚   â”‚   â”‚   hf_raise_for_status(r)                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3364 â”‚   â”‚   except HTTPError as err:                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3365 â”‚   â”‚   â”‚   if exist_ok and err.response.status_code == 409:          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   3366 â”‚   â”‚   â”‚   â”‚   # Repo already exists and \u001b[0m\u001b[1;36mexist_ok=True\u001b[1;35m             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:371 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ in hf_raise_for_status                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   368 â”‚   â”‚                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   369 â”‚   â”‚   # Convert \u001b[0m\u001b[1;36mHTTPError\u001b[1;35m into a \u001b[0m\u001b[1;36mHfHubHTTPError\u001b[1;35m to display reque â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   370 â”‚   â”‚   # as well (request id and/or server error message)             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 371 â”‚   â”‚   raise HfHubHTTPError(str(e), response=response) from e         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   372                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   373                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   374 def _format_error_message(message: str, request_id: Optional[str], ser â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mHfHubHTTPError: 401 Client Error: Unauthorized for url: \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[34m\u001b[0m\u001b[34mhttps://huggingface.co/api/repos/create\u001b[1;35m\u001b[1;35m (Request ID: \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mRoot=1-66d6cbc1-2f1339765c6fde0b25eee97e;e2bac93b-c75e-49d6-aa1d-ebcf80ec2d78)\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mInvalid username or password.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[31mAccelerate training job failed... See error message for details.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[31mFailed to run step \u001b[0m\u001b[1;36mtrain_model\u001b[31m after 1 retries. Exiting.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[31mAccelerate training job failed.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mTraceback (most recent call last):\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/integrations/huggingface/steps/accelerate_runner.py\", line 115, in inner\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    launch_command(args)\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1174, in launch_command\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    simple_launcher(args)\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 769, in simple_launcher\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35msubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '/app/code/FZZyFTUsKcOBYSnEBrsg.py', '--images-path', 'az://demo-zenmlartifactstore/hamza-faces', '--instance-name', 'sks htahir1', '--class-name', 'man', '--model-name', 'black-forest-labs/FLUX.1-dev', '--hf-repo-suffix', 'flux-dreambooth-hamza', '--prefix', 'A portrait photo of', '--resolution', '512', '--train-batch-size', '1', '--rank', '32', '--gradient-accumulation-steps', '1', '--learning-rate', '0.0002', '--lr-scheduler', 'constant', '--lr-warmup-steps', '0', '--max-train-steps', '1300', '--push-to-hub', '--checkpointing-steps', '1000', '--seed', '117']' returned non-zero exit status 1.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mThe above exception was the direct cause of the following exception:\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mTraceback (most recent call last):\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py\", line 292, in launch\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    self._run_step(\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py\", line 499, in _run_step\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    self._run_step_without_step_operator(\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py\", line 583, in _run_step_without_step_operator\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    runner.run(\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_runner.py\", line 198, in run\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    return_values = step_instance.call_entrypoint(\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/steps/base_step.py\", line 674, in call_entrypoint\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    return self.entrypoint(**validated_args)\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/integrations/huggingface/steps/accelerate_runner.py\", line 120, in inner\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m    raise RuntimeError(\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mRuntimeError: Accelerate training job failed.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[31mPipeline run \u001b[0m\u001b[1;36mdreambooth_pipeline-2024_09_03-08_40_19_549894\u001b[31m failed.\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/integrations/huggingface/steps â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /accelerate_runner.py:115 in inner                                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   112 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \"to find out more about supported argu â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   113 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   )                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   114 â”‚   â”‚   â”‚   â”‚   â”‚   try:                                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 115 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   launch_command(args)                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   116 â”‚   â”‚   â”‚   â”‚   â”‚   except Exception as e:                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   117 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   logger.error(                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   118 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \"Accelerate training job failed... See err â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py:1174   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ in launch_command                                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1171 â”‚   elif defaults is not None and defaults.compute_environment == Com â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1172 â”‚   â”‚   sagemaker_launcher(defaults, args)                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1173 â”‚   else:                                                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 1174 â”‚   â”‚   simple_launcher(args)                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1175                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1176                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   1177 def main():                                                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py:769 in â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ simple_launcher                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    766 â”‚   process.wait()                                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    767 â”‚   if process.returncode != 0:                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    768 â”‚   â”‚   if not args.quiet:                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â±  769 â”‚   â”‚   â”‚   raise subprocess.CalledProcessError(returncode=process.re â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    770 â”‚   â”‚   else:                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    771 â”‚   â”‚   â”‚   sys.exit(1)                                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    772                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mCalledProcessError: Command '['/opt/conda/bin/python', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'/app/code/FZZyFTUsKcOBYSnEBrsg.py', '--images-path', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'az://demo-zenmlartifactstore/hamza-faces', '--instance-name', 'sks htahir1', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'--class-name', 'man', '--model-name', 'black-forest-labs/FLUX.1-dev', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'--hf-repo-suffix', 'flux-dreambooth-hamza', '--prefix', 'A portrait photo of', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'--resolution', '512', '--train-batch-size', '1', '--rank', '32', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'--gradient-accumulation-steps', '1', '--learning-rate', '0.0002', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'--lr-scheduler', 'constant', '--lr-warmup-steps', '0', '--max-train-steps', \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m'1300', '--push-to-hub', '--checkpointing-steps', '1000', '--seed', '117']' \u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mreturned non-zero exit status 1.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mThe above exception was the direct cause of the following exception:\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35m\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/runpy.py:196 in _run_module_as_main                â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   193 â”‚   main_globals = sys.modules[\"__main__\"].__dict__                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   194 â”‚   if alter_argv:                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   195 â”‚   â”‚   sys.argv[0] = mod_spec.origin                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 196 â”‚   return _run_code(code, main_globals, None,                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   197 â”‚   â”‚   â”‚   â”‚   â”‚    \"__main__\", mod_spec)                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   198                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   199 def run_module(mod_name, init_globals=None,                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/runpy.py:86 in _run_code                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    83 â”‚   â”‚   â”‚   â”‚   â”‚      __loader__ = loader,                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    84 â”‚   â”‚   â”‚   â”‚   â”‚      __package__ = pkg_name,                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    85 â”‚   â”‚   â”‚   â”‚   â”‚      __spec__ = mod_spec)                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â±  86 â”‚   exec(code, run_globals)                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    87 â”‚   return run_globals                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    88                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    89 def _run_module_code(code, init_globals=None,                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/entrypoints/entrypoint.py:58   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ in <module>                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   55                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   56                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   57 if __name__ == \"__main__\":                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 58 â”‚   main()                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   59                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/entrypoints/entrypoint.py:54   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ in main                                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   51 â”‚   )                                                                   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   52 â”‚   entrypoint_config = entrypoint_config_class(arguments=remaining_arg â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   53 â”‚                                                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 54 â”‚   entrypoint_config.run()                                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   55                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   56                                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   57 if __name__ == \"__main__\":                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/entrypoints/step_entrypoint_co â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ nfiguration.py:163 in run                                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   160 â”‚   â”‚   pipeline_name = deployment.pipeline_configuration.name         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   161 â”‚   â”‚                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   162 â”‚   â”‚   step = deployment.step_configurations[step_name]               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 163 â”‚   â”‚   self._run_step(step, deployment=deployment)                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   164 â”‚   â”‚                                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   165 â”‚   â”‚   self.post_run(                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   166 â”‚   â”‚   â”‚   pipeline_name=pipeline_name,                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/entrypoints/step_entrypoint_co â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ nfiguration.py:183 in _run_step                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   180 â”‚   â”‚   \"\"\"                                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   181 â”‚   â”‚   orchestrator = Client().active_stack.orchestrator              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   182 â”‚   â”‚   orchestrator._prepare_run(deployment=deployment)               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 183 â”‚   â”‚   orchestrator.run_step(step=step)                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   184                                                                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/orchestrators/base_orchestrato â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ r.py:207 in run_step                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   204 â”‚   â”‚   â”‚   step=step,                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   205 â”‚   â”‚   â”‚   orchestrator_run_id=self.get_orchestrator_run_id(),        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   206 â”‚   â”‚   )                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 207 â”‚   â”‚   launcher.launch()                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   208 â”‚                                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   209 â”‚   @staticmethod                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   210 â”‚   def requires_resources_in_orchestration_environment(               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ :292 in launch                                                               â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   289 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   return None                        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   290 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   291 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   force_write_logs = _bypass             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 292 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   self._run_step(                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   293 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   pipeline_run=pipeline_run,             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   294 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   step_run=step_run_response,            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   295 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   last_retry=last_retry,                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ :499 in _run_step                                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   496 â”‚   â”‚   â”‚   â”‚   â”‚   last_retry=last_retry,                             â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   497 â”‚   â”‚   â”‚   â”‚   )                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   498 â”‚   â”‚   â”‚   else:                                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 499 â”‚   â”‚   â”‚   â”‚   self._run_step_without_step_operator(                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   500 â”‚   â”‚   â”‚   â”‚   â”‚   pipeline_run=pipeline_run,                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   501 â”‚   â”‚   â”‚   â”‚   â”‚   step_run=step_run,                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   502 â”‚   â”‚   â”‚   â”‚   â”‚   step_run_info=step_run_info,                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_launcher.py â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ :583 in _run_step_without_step_operator                                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   580 â”‚   â”‚   if last_retry:                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   581 â”‚   â”‚   â”‚   os.environ[ENV_ZENML_IGNORE_FAILURE_HOOK] = \"false\"        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   582 â”‚   â”‚   runner = StepRunner(step=self._step, stack=self._stack)        â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 583 â”‚   â”‚   runner.run(                                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   584 â”‚   â”‚   â”‚   pipeline_run=pipeline_run,                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   585 â”‚   â”‚   â”‚   step_run=step_run,                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   586 â”‚   â”‚   â”‚   input_artifacts=input_artifacts,                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/orchestrators/step_runner.py:1 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ 98 in run                                                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   195 â”‚   â”‚   â”‚   â”‚                                                          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   196 â”‚   â”‚   â”‚   â”‚   step_failed = False                                    â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   197 â”‚   â”‚   â”‚   â”‚   try:                                                   â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 198 â”‚   â”‚   â”‚   â”‚   â”‚   return_values = step_instance.call_entrypoint(     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   199 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   **function_params                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   200 â”‚   â”‚   â”‚   â”‚   â”‚   )                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   201 â”‚   â”‚   â”‚   â”‚   except BaseException as step_exception:  # noqa: E722  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/steps/base_step.py:674 in      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ call_entrypoint                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    671 â”‚   â”‚   â”‚   â”‚   \"pydantic error above for more details.\"              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    672 â”‚   â”‚   â”‚   ) from e                                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    673 â”‚   â”‚                                                                 â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â±  674 â”‚   â”‚   return self.entrypoint(**validated_args)                      â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    675 â”‚                                                                     â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    676 â”‚   @property                                                         â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚    677 â”‚   def name(self) -> str:                                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /opt/conda/lib/python3.10/site-packages/zenml/integrations/huggingface/steps â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ /accelerate_runner.py:120 in inner                                           â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚                                                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   117 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   logger.error(                                  â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   118 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \"Accelerate training job failed... See err â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   119 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   )                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚ â± 120 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   raise RuntimeError(                            â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   121 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \"Accelerate training job failed.\"          â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   122 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   ) from e                                       â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ”‚   123 â”‚   â”‚   â”‚   â”‚   â”‚   else:                                              â”‚\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mRuntimeError: Accelerate training job failed.\u001b[0m\u001b[0m\n",
      "\u001b[1;35mException in thread Thread-1 (_run_node):\u001b[0m\n",
      "\u001b[1;35mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[1;35m  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\u001b[0m\n",
      "\u001b[1;35m    self.run()\u001b[0m\n",
      "\u001b[1;35m  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\u001b[0m\n",
      "\u001b[1;35m    self._target(*self._args, **self._kwargs)\u001b[0m\n",
      "\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/orchestrators/dag_runner.py\", line 126, in _run_node\u001b[0m\n",
      "\u001b[1;35m    self.run_fn(node)\u001b[0m\n",
      "\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/integrations/kubernetes/orchestrators/kubernetes_orchestrator_entrypoint.py\", line 143, in run_step_on_kubernetes\u001b[0m\n",
      "\u001b[1;35m    kube_utils.wait_pod(\u001b[0m\n",
      "\u001b[1;35m  File \"/opt/conda/lib/python3.10/site-packages/zenml/integrations/kubernetes/orchestrators/kube_utils.py\", line 240, in wait_pod\u001b[0m\n",
      "\u001b[1;35m    raise RuntimeError(f\"Pod \u001b[0m\u001b[1;36m{namespace}:{pod_name}\u001b[1;35m failed.\")\u001b[0m\n",
      "\u001b[1;35mRuntimeError: Pod \u001b[0m\u001b[1;36mzenml:dreambooth-pipeline-0640a0003c702fa7797dc499afbc38b1-train-model\u001b[1;35m failed.\u001b[0m\n",
      "\u001b[1;35m\u001b[33mNode \u001b[0m\u001b[1;36mbatch_inference\u001b[33m was never run, because it was still waiting for the following nodes: \u001b[0m\u001b[1;36m['train_model']\u001b[33m.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[33mNode \u001b[0m\u001b[1;36mimage_to_video\u001b[33m was never run, because it was still waiting for the following nodes: \u001b[0m\u001b[1;36m['batch_inference']\u001b[33m.\u001b[0m\u001b[0m\n",
      "\u001b[1;35m\u001b[1;35mOrchestration pod completed.\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pipeline launched! Sit back, relax, and prepare to be amazed! ğŸ¿\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pipeline launched! Sit back, relax, and prepare to be amazed! ğŸ¿\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dreambooth_pipeline.with_options(config_path=\"configs/k8s_run_refactored_multi_video.yaml\")()\n",
    "\n",
    "print(\"Pipeline launched! Sit back, relax, and prepare to be amazed! ğŸ¿\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it, folks! You've just built and launched a kickass pipeline for personalized AI model generation. From loading data to training models, from generating images to creating videos - you've done it all!\n",
    "\n",
    "Remember, this is just the beginning. Feel free to tweak, adjust, and experiment with the parameters to see what kind of magic you can create. The AI world is your oyster, and you've got the tools to make some serious pearls!\n",
    "\n",
    "Happy coding, and may your models be ever accurate and your latency low! ğŸš€ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
