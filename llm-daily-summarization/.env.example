# LLM Summarization Pipeline Environment Variables

# === LLM Provider Configuration ===
# Google Cloud / Vertex AI
GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
GOOGLE_CLOUD_PROJECT="project-id"  # Replace with your Google Cloud project ID
GOOGLE_CLOUD_REGION="europe-west3"

# === Observability and Monitoring ===
# Langfuse (LLM Observability)
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_HOST="https://cloud.langfuse.com"
LANGFUSE_PROJECT_ID="your-langfuse-project-id"  # Required for generating direct trace URLs

# === Data Sources ===
# Discord Bot
DISCORD_BOT_TOKEN="your-discord-bot-token"

# Slack Bot
SLACK_BOT_TOKEN="xoxb-your-slack-bot-token"
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."

# === Output Destinations ===
# Notion Integration
NOTION_TOKEN="secret_your-notion-integration-token"
NOTION_SUMMARIES_DB_ID="your-summaries-database-id"
NOTION_TASKS_DB_ID="your-tasks-database-id"

# GitHub (for creating issues)
GITHUB_TOKEN="ghp_your-github-token"
GITHUB_REPO_OWNER="your-username"
GITHUB_REPO_NAME="your-repo"

# === ZenML Configuration ===
ZENML_LOGGING_VERBOSITY="INFO"
ZENML_ANALYTICS_OPT_IN="false"
AUTO_OPEN_DASHBOARD="false"

# === Development Settings ===
# Enable/disable various features for testing
USE_MOCK_DATA="true"  # Set to false for real data sources
ENABLE_LANGFUSE_TRACING="true"
ENABLE_COST_TRACKING="true"

# === Optional: Advanced Settings ===
# Model configuration overrides
LLM_MODEL_NAME="gemini-2.5-flash"
LLM_MAX_TOKENS="4000"
LLM_TEMPERATURE="0.1"

# Processing limits
MAX_MESSAGES_PER_CONVERSATION="500"
MIN_MESSAGE_LENGTH="5"
DAYS_BACK="1"