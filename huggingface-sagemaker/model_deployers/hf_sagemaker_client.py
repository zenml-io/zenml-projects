#  Copyright (c) ZenML GmbH 2022. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at:
#
#       https://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
#  or implied. See the License for the specific language governing
#  permissions and limitations under the License.
"""Implementation of the HF Sagemaker client for ZenML."""

import json
import re
import time
from typing import Any, Dict, List, Optional

import sagemaker
from pydantic import BaseModel, Field, ValidationError
from zenml.logger import get_logger

logger = get_logger(__name__)


class HFSagemakerDeployment(BaseModel):
    """ """

    kind: str = Field(SELDON_DEPLOYMENT_KIND, const=True)
    apiVersion: str = Field(SELDON_DEPLOYMENT_API_VERSION, const=True)
    metadata: SeldonDeploymentMetadata
    spec: SeldonDeploymentSpec
    status: Optional[SeldonDeploymentStatus] = None

    def __str__(self) -> str:
        """Returns a string representation of the Seldon Deployment.

        Returns:
            A string representation of the Seldon Deployment.
        """
        return json.dumps(self.dict(exclude_none=True), indent=4)

    @classmethod
    def build(
        cls,
        name: Optional[str] = None,
        model_uri: Optional[str] = None,
        model_name: Optional[str] = None,
        implementation: Optional[str] = None,
        parameters: Optional[List[SeldonDeploymentPredictorParameter]] = None,
        engineResources: Optional[SeldonResourceRequirements] = None,
        secret_name: Optional[str] = None,
        labels: Optional[Dict[str, str]] = None,
        annotations: Optional[Dict[str, str]] = None,
        is_custom_deployment: Optional[bool] = False,
        spec: Optional[Dict[Any, Any]] = None,
    ) -> "SeldonDeployment":
        """Build a basic Seldon Deployment object.

        Args:
            name: The name of the Seldon Deployment. If not explicitly passed,
                a unique name is autogenerated.
            model_uri: The URI of the model.
            model_name: The name of the model.
            implementation: The implementation of the model.
            parameters: The predictor graph parameters.
            engineResources: The resources to be allocated to the model.
            secret_name: The name of the Kubernetes secret containing
                environment variable values (e.g. with credentials for the
                artifact store) to use with the deployment service.
            labels: A dictionary of labels to apply to the Seldon Deployment.
            annotations: A dictionary of annotations to apply to the Seldon
                Deployment.
            spec: A Kubernetes pod spec to use for the Seldon Deployment.
            is_custom_deployment: Whether the Seldon Deployment is a custom or a built-in one.

        Returns:
            A minimal SeldonDeployment object built from the provided
            parameters.
        """
        if not name:
            name = f"zenml-{time.time()}"

        if labels is None:
            labels = {}
        if annotations is None:
            annotations = {}

        if is_custom_deployment:
            predictors = [
                SeldonDeploymentPredictor(
                    name=model_name or "",
                    graph=SeldonDeploymentPredictiveUnit(
                        name="classifier",
                        type=SeldonDeploymentPredictiveUnitType.MODEL,
                        parameters=parameters,
                    ),
                    engineResources=engineResources,
                    componentSpecs=[
                        SeldonDeploymentComponentSpecs(
                            spec=spec
                            # TODO [HIGH]: Add support for other component types (e.g. graph)
                        )
                    ],
                )
            ]
        else:
            predictors = [
                SeldonDeploymentPredictor(
                    name=model_name or "",
                    graph=SeldonDeploymentPredictiveUnit(
                        name="classifier",
                        type=SeldonDeploymentPredictiveUnitType.MODEL,
                        modelUri=model_uri or "",
                        implementation=implementation or "",
                        envSecretRefName=secret_name,
                        parameters=parameters,
                    ),
                    engineResources=engineResources,
                )
            ]

        return SeldonDeployment(
            metadata=SeldonDeploymentMetadata(
                name=name, labels=labels, annotations=annotations
            ),
            spec=SeldonDeploymentSpec(name=name, predictors=predictors),
        )

    def is_managed_by_zenml(self) -> bool:
        """Checks if this Seldon Deployment is managed by ZenML.

        The convention used to differentiate between SeldonDeployment instances
        that are managed by ZenML and those that are not is to set the `app`
        label value to `zenml`.

        Returns:
            True if the Seldon Deployment is managed by ZenML, False
            otherwise.
        """
        return self.metadata.labels.get("app") == "zenml"

    def mark_as_managed_by_zenml(self) -> None:
        """Marks this Seldon Deployment as managed by ZenML.

        The convention used to differentiate between SeldonDeployment instances
        that are managed by ZenML and those that are not is to set the `app`
        label value to `zenml`.
        """
        self.metadata.labels["app"] = "zenml"

    @property
    def name(self) -> str:
        """Returns the name of this Seldon Deployment.

        This is just a shortcut for `self.metadata.name`.

        Returns:
            The name of this Seldon Deployment.
        """
        return self.metadata.name

    @property
    def state(self) -> SeldonDeploymentStatusState:
        """The state of the Seldon Deployment.

        Returns:
            The state of the Seldon Deployment.
        """
        if not self.status:
            return SeldonDeploymentStatusState.UNKNOWN
        return self.status.state

    def is_pending(self) -> bool:
        """Checks if the Seldon Deployment is in a pending state.

        Returns:
            True if the Seldon Deployment is pending, False otherwise.
        """
        return self.state == SeldonDeploymentStatusState.CREATING

    def is_available(self) -> bool:
        """Checks if the Seldon Deployment is in an available state.

        Returns:
            True if the Seldon Deployment is available, False otherwise.
        """
        return self.state == SeldonDeploymentStatusState.AVAILABLE

    def is_failed(self) -> bool:
        """Checks if the Seldon Deployment is in a failed state.

        Returns:
            True if the Seldon Deployment is failed, False otherwise.
        """
        return self.state == SeldonDeploymentStatusState.FAILED

    def get_error(self) -> Optional[str]:
        """Get a message describing the error, if in an error state.

        Returns:
            A message describing the error, if in an error state, otherwise
            None.
        """
        if self.status and self.is_failed():
            return self.status.description
        return None

    def get_pending_message(self) -> Optional[str]:
        """Get a message describing the pending conditions of the Seldon Deployment.

        Returns:
            A message describing the pending condition of the Seldon
            Deployment, or None, if no conditions are pending.
        """
        if not self.status or not self.status.conditions:
            return None
        ready_condition_message = [
            c.message
            for c in self.status.conditions
            if c.type == "Ready" and not c.status
        ]
        if not ready_condition_message:
            return None
        return ready_condition_message[0]

    class Config:
        """Pydantic configuration class."""

        # validate attribute assignments
        validate_assignment = True
        # Ignore extra attributes from the CRD that are not reflected here
        extra = "ignore"


class HFSagemakerClientError(Exception):
    """Base exception class for all exceptions raised by the HFSagemakerClient."""


class HFSagemakerClientTimeout(HFSagemakerClientError):
    """Raised when the HFSagemaker client timed out while waiting for a resource to reach the expected status."""


class HFSagemakerDeploymentExistsError(HFSagemakerClientError):
    """Raised when a HFSagemakerDeployment resource cannot be created because a resource with the same name already exists."""


class HFSagemakerDeploymentNotFoundError(HFSagemakerClientError):
    """Raised when a particular HFSagemakerDeployment resource is not found or is not managed by ZenML."""


class HFSagemakerClient:
    """A client for interacting with HFSagemaker Deployments."""

    def __init__(self, sagemaker_session: sagemaker.Session):
        """Initialize a HFSagemaker Core client.

        Args:
            context: the Kubernetes context to use.
            namespace: the Kubernetes namespace to use.
            kube_client: a Kubernetes client to use.
        """
        self._sagemaker_session = sagemaker_session

    @staticmethod
    def sanitize_tags(tags: Dict[str, str]) -> None:
        """ """
        for key, value in tags.items():
            # Kubernetes labels must be alphanumeric, no longer than
            # 63 characters, and must begin and end with an alphanumeric
            # character ([a-z0-9A-Z])
            tags[key] = re.sub(r"[^0-9a-zA-Z-_\.]+", "_", value)[:63].strip("-_.")

    def create_deployment(
        self,
        deployment: HFSagemakerDeployment,
        poll_timeout: int = 0,
    ) -> HFSagemakerDeployment:
        """Create a HFSagemaker Core deployment resource.

        Args:
            deployment: the HFSagemaker Core deployment resource to create
            poll_timeout: the maximum time to wait for the deployment to become
                available or to fail. If set to 0, the function will return
                immediately without checking the deployment status. If a timeout
                occurs and the deployment is still pending creation, it will
                be returned anyway and no exception will be raised.

        Returns:
            the created HFSagemaker Core deployment resource with updated status.

        Raises:
            HFSagemakerDeploymentExistsError: if a deployment with the same name
                already exists.
            HFSagemakerClientError: if an unknown error occurs during the creation of
                the deployment.
        """
        try:
            logger.debug(f"Creating HFSagemakerDeployment resource: {deployment}")

            # mark the deployment as managed by ZenML, to differentiate
            # between deployments that are created by ZenML and those that
            # are not
            deployment.mark_as_managed_by_zenml()

            body_deploy = deployment.dict(exclude_none=True)
            response = self._custom_objects_api.create_namespaced_custom_object(
                group="machinelearning.seldon.io",
                version="v1",
                namespace=self._namespace,
                plural="seldondeployments",
                body=body_deploy,
                _request_timeout=poll_timeout or None,
            )
            logger.debug("HFSagemaker Core API response: %s", response)
        except k8s_client.rest.ApiException as e:
            logger.error(
                "Exception when creating HFSagemakerDeployment resource: %s", str(e)
            )
            if e.status == 409:
                raise HFSagemakerDeploymentExistsError(
                    f"A deployment with the name {deployment.name} "
                    f"already exists in namespace {self._namespace}"
                )
            raise HFSagemakerClientError(
                "Exception when creating HFSagemakerDeployment resource"
            ) from e

        created_deployment = self.get_deployment(name=deployment.name)

        while poll_timeout > 0 and created_deployment.is_pending():
            time.sleep(5)
            poll_timeout -= 5
            created_deployment = self.get_deployment(name=deployment.name)

        return created_deployment

    def delete_deployment(
        self,
        name: str,
        force: bool = False,
        poll_timeout: int = 0,
    ) -> None:
        """Delete a HFSagemaker Core deployment resource managed by ZenML.

        Args:
            name: the name of the HFSagemaker Core deployment resource to delete.
            force: if True, the deployment deletion will be forced (the graceful
                period will be set to zero).
            poll_timeout: the maximum time to wait for the deployment to be
                deleted. If set to 0, the function will return immediately
                without checking the deployment status. If a timeout
                occurs and the deployment still exists, this method will
                return and no exception will be raised.

        Raises:
            HFSagemakerClientError: if an unknown error occurs during the deployment
                removal.
        """
        try:
            logger.debug(f"Deleting HFSagemakerDeployment resource: {name}")

            # call `get_deployment` to check that the deployment exists
            # and is managed by ZenML. It will raise
            # a HFSagemakerDeploymentNotFoundError otherwise
            self.get_deployment(name=name)

            response = self._custom_objects_api.delete_namespaced_custom_object(
                group="machinelearning.seldon.io",
                version="v1",
                namespace=self._namespace,
                plural="seldondeployments",
                name=name,
                _request_timeout=poll_timeout or None,
                grace_period_seconds=0 if force else None,
            )
            logger.debug("HFSagemaker Core API response: %s", response)
        except k8s_client.rest.ApiException as e:
            logger.error(
                "Exception when deleting HFSagemakerDeployment resource %s: %s",
                name,
                str(e),
            )
            raise HFSagemakerClientError(
                f"Exception when deleting HFSagemakerDeployment resource {name}"
            ) from e

        while poll_timeout > 0:
            try:
                self.get_deployment(name=name)
            except HFSagemakerDeploymentNotFoundError:
                return
            time.sleep(5)
            poll_timeout -= 5

    def update_deployment(
        self,
        deployment: HFSagemakerDeployment,
        poll_timeout: int = 0,
    ) -> HFSagemakerDeployment:
        """Update a HFSagemaker Core deployment resource.

        Args:
            deployment: the HFSagemaker Core deployment resource to update
            poll_timeout: the maximum time to wait for the deployment to become
                available or to fail. If set to 0, the function will return
                immediately without checking the deployment status. If a timeout
                occurs and the deployment is still pending creation, it will
                be returned anyway and no exception will be raised.

        Returns:
            the updated HFSagemaker Core deployment resource with updated status.

        Raises:
            HFSagemakerClientError: if an unknown error occurs while updating the
                deployment.
        """
        try:
            logger.debug(f"Updating HFSagemakerDeployment resource: {deployment.name}")

            # mark the deployment as managed by ZenML, to differentiate
            # between deployments that are created by ZenML and those that
            # are not
            deployment.mark_as_managed_by_zenml()

            # call `get_deployment` to check that the deployment exists
            # and is managed by ZenML. It will raise
            # a HFSagemakerDeploymentNotFoundError otherwise
            self.get_deployment(name=deployment.name)

            response = self._custom_objects_api.patch_namespaced_custom_object(
                group="machinelearning.seldon.io",
                version="v1",
                namespace=self._namespace,
                plural="seldondeployments",
                name=deployment.name,
                body=deployment.dict(exclude_none=True),
                _request_timeout=poll_timeout or None,
            )
            logger.debug("HFSagemaker Core API response: %s", response)
        except k8s_client.rest.ApiException as e:
            logger.error(
                "Exception when updating HFSagemakerDeployment resource: %s", str(e)
            )
            raise HFSagemakerClientError(
                "Exception when creating HFSagemakerDeployment resource"
            ) from e

        updated_deployment = self.get_deployment(name=deployment.name)

        while poll_timeout > 0 and updated_deployment.is_pending():
            time.sleep(5)
            poll_timeout -= 5
            updated_deployment = self.get_deployment(name=deployment.name)

        return updated_deployment

    def get_deployment(self, name: str) -> HFSagemakerDeployment:
        """Get a ZenML managed HFSagemaker Core deployment resource by name.

        Args:
            name: the name of the HFSagemaker Core deployment resource to fetch.

        Returns:
            The HFSagemaker Core deployment resource.

        Raises:
            HFSagemakerDeploymentNotFoundError: if the deployment resource cannot
                be found or is not managed by ZenML.
            HFSagemakerClientError: if an unknown error occurs while fetching
                the deployment.
        """
        try:
            logger.debug(f"Retrieving HFSagemakerDeployment resource: {name}")

            response = self._custom_objects_api.get_namespaced_custom_object(
                group="machinelearning.seldon.io",
                version="v1",
                namespace=self._namespace,
                plural="seldondeployments",
                name=name,
            )
            logger.debug("HFSagemaker Core API response: %s", response)
            try:
                deployment = HFSagemakerDeployment(**response)
            except ValidationError as e:
                logger.error(
                    "Invalid HFSagemaker Core deployment resource: %s\n%s",
                    str(e),
                    str(response),
                )
                raise HFSagemakerDeploymentNotFoundError(
                    f"HFSagemakerDeployment resource {name} could not be parsed"
                )

            # Only HFSagemaker deployments managed by ZenML are returned
            if not deployment.is_managed_by_zenml():
                raise HFSagemakerDeploymentNotFoundError(
                    f"HFSagemaker Deployment {name} is not managed by ZenML"
                )
            return deployment

        except k8s_client.rest.ApiException as e:
            if e.status == 404:
                raise HFSagemakerDeploymentNotFoundError(
                    f"HFSagemakerDeployment resource not found: {name}"
                ) from e
            logger.error(
                "Exception when fetching HFSagemakerDeployment resource %s: %s",
                name,
                str(e),
            )
            raise HFSagemakerClientError(
                f"Unexpected exception when fetching HFSagemakerDeployment "
                f"resource: {name}"
            ) from e

    def find_deployments(
        self,
        tags: Optional[Dict[str, str]] = None,
    ) -> List[sagemaker.Predictor]:
        """ """
        tags = tags or {}
        # Initialize a list to store the filtered SageMaker endpoints
        filtered_endpoints = []

        def initialize_sagemaker_predictors(filtered_endpoints, sagemaker_session):
            predictors = []

            for endpoint in filtered_endpoints:
                # Create a SageMaker predictor for the endpoint
                predictor = sagemaker.Predictor(
                    endpoint_name=endpoint["EndpointName"],
                    sagemaker_session=sagemaker_session,
                )
                predictors.append(predictor)

            return predictors

        try:
            logger.debug("Searching for SageMaker endpoints...")

            # Get the SageMaker session
            sagemaker_session = self.get_sagemaker_session()

            # List all SageMaker endpoints
            endpoints = sagemaker_session.list_endpoints()

            for endpoint in endpoints["Endpoints"]:
                # Get the tags associated with the endpoint
                response = sagemaker_session.list_tags(
                    ResourceArn=endpoint["EndpointArn"]
                )
                endpoint_tags = response.get("Tags", [])

                # Check if all tags in the 'tags' parameter are present in 'endpoint_tags'
                all_tags_present = all(
                    all(
                        tag_key in endpoint_tags and endpoint_tags[tag_key] == tag_value
                        for tag_key, tag_value in tags.items()
                    )
                )

                if all_tags_present:
                    # If all specified tags are present in the endpoint's tags, add it to the filtered endpoints list
                    filtered_endpoints.append(endpoint)

            # Now, 'filtered_endpoints' will contain the SageMaker endpoints that match all specified tags
            # Process the filtered endpoints as needed, e.g., create SageMaker predictors

        except Exception as e:
            # Handle exceptions appropriately
            logger.error(f"An error occurred: {str(e)}")

        return initialize_sagemaker_predictors(filtered_endpoints, sagemaker_session)

    @staticmethod
    def sanitize_tags(tags: Dict[str, str]) -> None:
        """ """
        for key, value in tags.items():
            # Kubernetes labels must be alphanumeric, no longer than
            # 63 characters, and must begin and end with an alphanumeric
            # character ([a-z0-9A-Z])
            tags[key] = re.sub(r"[^0-9a-zA-Z-_\.]+", "_", value)[:63].strip("-_.")
