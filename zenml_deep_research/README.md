# üîç ZenML Deep Research Agent

A production-ready MLOps pipeline for conducting deep, comprehensive research on any topic using LLMs and web search capabilities.

<div align="center">
  <img alt="Research Pipeline Visualization" src="assets/pipeline_visualization.png" width="70%">
  <p><em>ZenML Deep Research pipeline flow</em></p>
</div>

## üéØ Overview

The ZenML Deep Research Agent is a scalable, modular pipeline that automates in-depth research on any topic. It:

- Creates a structured outline based on your research query
- Researches each section through targeted web searches and LLM analysis
- Iteratively refines content through reflection cycles
- Produces a comprehensive, well-formatted research report
- Visualizes the research process and report structure in the ZenML dashboard

This project transforms exploratory notebook-based research into a production-grade, reproducible, and transparent process using the ZenML MLOps framework.

## üìù Example Research Results

The Deep Research Agent produces comprehensive, well-structured reports on any topic. Here's an example of research conducted on quantum computing:

<div align="center">
  <img alt="Sample Research Report" src="assets/sample_report.png" width="70%">
  <p><em>Sample report generated by the Deep Research Agent</em></p>
</div>

## üöÄ Pipeline Architecture

The pipeline breaks down the research process into granular steps for maximum modularity and control:

1. **Query Decomposition**: Break down the main query into specific sub-questions
2. **Parallel Information Gathering**: Fetch data for each sub-question using optimized search queries
3. **Information Validation & Synthesis**: Validate sources, remove redundancies, and synthesize findings
4. **Cross-Viewpoint Analysis**: Analyze discrepancies and agreements between different perspectives
5. **Iterative Reflection**: Self-critique research output to identify gaps and trigger additional searches
6. **Final Report Generation**: Compile all synthesized information into a coherent report

This granular approach enables:
- Better reproducibility and caching of intermediate results
- Easier debugging and monitoring of specific research stages
- More flexible reconfiguration of individual components
- Enhanced transparency into how the research is conducted

## üí° Under the Hood

- **LLM Integration**: Uses litellm for flexible access to various LLM providers
- **Web Research**: Utilizes Tavily API for targeted internet searches
- **ZenML Orchestration**: Manages pipeline flow, artifacts, and caching
- **Reproducibility**: Track every step, parameter, and output via ZenML
- **Visualizations**: Interactive visualizations of the research structure and progress
- **Report Generation**: Uses static HTML templates for consistent, high-quality reports

## üõ†Ô∏è Getting Started

### Prerequisites

- Python 3.9+
- ZenML installed and configured
- API key for your preferred LLM provider (configured with litellm)
- Tavily API key

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd zenml_deep_research

# Install dependencies
pip install -r requirements.txt

# Set up API keys
export OPENAI_API_KEY=your_openai_key  # Or another LLM provider key
export TAVILY_API_KEY=your_tavily_key

# Initialize ZenML (if needed)
zenml init
```

### Running the Pipeline

#### Basic Usage

```bash
# Run with default configuration
python run.py
```

The default configuration and research query are defined in `configs/enhanced_research.yaml`.

#### Using Different Configurations

```bash
# Run with a custom configuration file
python run.py --config configs/custom_enhanced_config.yaml

# Override the research query from command line
python run.py --query "My research topic"

# Combine custom config and query
python run.py --config configs/custom_enhanced_config.yaml --query "My research topic"
```

### Advanced Options

```bash
# Enable debug logging
python run.py --debug

# Disable caching for a fresh run
python run.py --no-cache

# Specify a log file
python run.py --log-file research.log
```

## üìä Visualizing Research Process

The pipeline includes built-in visualizations to help you understand and monitor the research process:

### Viewing Visualizations

After running the pipeline, you can view the visualizations in the ZenML dashboard:

1. Start the ZenML dashboard:
   ```bash
   zenml up
   ```

2. Navigate to the "Runs" tab in the dashboard
3. Select your pipeline run
4. Explore visualizations for each step:
   - **report_structure_step**: View the initial report structure and outline
   - **paragraph_research_step**: See the research progress for each paragraph
   - **report_formatting_step**: View the final formatted report

### Visualization Features

The visualizations provide:
- An overview of the report structure
- Details of each paragraph's research status
- Search history and source information
- Progress through reflection iterations
- Professionally formatted HTML reports with static templates

### Sample Visualization

Here's what the report structure visualization looks like:

```
Report Structure:
‚îú‚îÄ‚îÄ Introduction
‚îÇ   ‚îî‚îÄ‚îÄ Initial understanding of the topic
‚îú‚îÄ‚îÄ Historical Background
‚îÇ   ‚îî‚îÄ‚îÄ Evolution and key developments
‚îú‚îÄ‚îÄ Current State
‚îÇ   ‚îî‚îÄ‚îÄ Latest advancements and implementations
‚îî‚îÄ‚îÄ Conclusion
    ‚îî‚îÄ‚îÄ Summary and future implications
```

## üìÅ Project Structure

```
zenml_deep_research/
‚îú‚îÄ‚îÄ configs/             # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ research_config.yaml
‚îú‚îÄ‚îÄ pipelines/           # ZenML pipeline definitions
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ research_pipeline.py
‚îú‚îÄ‚îÄ steps/               # ZenML pipeline steps
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ load_config.py
‚îÇ   ‚îú‚îÄ‚îÄ report_structure_step.py
‚îÇ   ‚îú‚îÄ‚îÄ paragraph_research_step.py
‚îÇ   ‚îî‚îÄ‚îÄ report_formatting_step.py
‚îú‚îÄ‚îÄ utils/               # Utility functions and helpers
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_models.py
‚îÇ   ‚îú‚îÄ‚îÄ helper_functions.py
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py        # Contains static HTML templates for report generation
‚îÇ   ‚îî‚îÄ‚îÄ state_visualizer.py  # Custom visualizer for the State class
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ requirements.txt     # Project dependencies
‚îú‚îÄ‚îÄ logging_config.py    # Logging configuration
‚îú‚îÄ‚îÄ README.md            # Project documentation
‚îî‚îÄ‚îÄ run.py               # Main script to run the pipeline
```

## üîß Customization

The project supports two levels of customization:

### 1. Step Parameters

You can customize the research behavior directly through command-line parameters:

```bash
# Run with more reflection cycles
python run.py --query "Your query" --num-reflections 3

# Adjust search parameters (available as step parameters)
python run.py --query "Your query" --num-reflections 4
```

Each step has its own parameters with sensible defaults that can be customized by modifying the step definitions.

### 2. Pipeline Configuration

For pipeline-level settings, modify the configuration file:

```yaml
# configs/pipeline_config.yaml

# Pipeline settings
enable_cache: true

# Research parameters
step:
  report_structure_step:
    parameters:
      query: "Default research query"  # The research query/topic to investigate
  paragraph_research_step:
    parameters:
      num_reflections: 2  # Number of reflection cycles to perform per paragraph
  
# Environment settings
settings:
  docker:
    requirements:
      - litellm>=1.0.0
      - tavily-python>=0.2.8
      - PyYAML>=6.0
      - click>=8.0.0
      - pydantic>=2.0.0
      - typing_extensions>=4.0.0
```

To use a custom configuration file:

```bash
python run.py --config configs/custom_pipeline.yaml
```

### Available Configurations

| Config File | Description | Key Parameters |
|-------------|-------------|----------------|
| `enhanced_research.yaml` | Default research configuration | Climate change query, 2 additional searches |
| `thorough_research.yaml` | In-depth analysis | More comprehensive search, 4 additional searches |
| `quick_research.yaml` | Faster results | 1 additional search, fewer results per search |
| `daily_trends.yaml` | Research on recent topics | 24-hour search recency, disable cache |
| `viewpoint_analysis.yaml` | Focus on comparing perspectives | Extended viewpoint categories, 3 additional searches |

You can create additional configuration files by copying and modifying the base configuration files above.

## üìà Example Use Cases

- **Academic Research**: Rapidly generate preliminary research on academic topics
- **Business Intelligence**: Stay informed on industry trends and competitive landscape
- **Content Creation**: Develop well-researched content for articles, blogs, or reports
- **Decision Support**: Gather comprehensive information for informed decision-making

## üîÑ Integration Possibilities

This pipeline can integrate with:

- **Document Storage**: Save reports to database or document management systems
- **Web Applications**: Power research functionality in web interfaces
- **Alerting Systems**: Schedule research on key topics and receive regular reports
- **Other ZenML Pipelines**: Chain with downstream analysis or processing

## üìÑ License

This project is licensed under the Apache License 2.0.
