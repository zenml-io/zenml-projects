{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning custom embedding models on synthetic data\n",
    "\n",
    "Bootstrapping and maintaining production-ready RAG pipelines, requires optimizaiton various components like the LLM, vector database, embeddings and rerankers. Within this notbeook we will showcase how you can optimize and maintain your embedding models through synthetic data and human feedback. Besides ZenML, we will do this by using two open source libraries: `argilla` and `distilabel`. Both of these libraries focus optimizing model outputs through improving data quality, however, each one of them take a diferent approach to tackle the same problem. `distilabel` provides a scalable and reliable approach to distilling knowledge from LLMs by generating synthetic data or providing AI feedback with LLMs as judges. `argilla` enables AI engineers and domain experts to collaborate on data projects by allowing them to organize and explore data through within an interactive and engagig UI. Both libraries can be used individually but they work better together.\n",
    "\n",
    "- ⚗️ distilabel is a framework for synthetic data and AI feedback - [docs](distilabel.argilla.io)\n",
    "- Argilla is a collaboration tool for AI engineers and domain experts to build high-quality datasets - [docs](docs.argilla.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset - vibe check\n",
    "\n",
    "Before starting any project, it is always important to look at your data. Our data is publicly [available on the Hugging Face Hub](https://huggingface.co/datasets/zenml/rag_qa_embedding_questions_0_60_0) so we can have a quick look through their dataset viewer within an embedded iFrame. \n",
    "\n",
    "As we can see, our dataset contains a column called `page_content`, which was obtained from the ZenML docs.\n",
    "\n",
    "TODO: add context about `page_content`, chunking etc. Could we look into semantic chunking?\n",
    "\n",
    "<iframe src=\"https://huggingface.co/datasets/zenml/rag_qa_embedding_questions_0_60_0/embed/viewer\" frameborder=\"0\" width=\"100%\" height=\"560px\"></iframe>\n",
    "\n",
    "Alternatively, we can load the entire dataset to disk with `datasets.load_dataset`. There is only a single split (`train`), which we will provide as argument to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_name = \"zenml/rag_qa_embedding_questions_0_60_0\"\n",
    "\n",
    "dataset = load_dataset(repo_name, split=\"train\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic query generation with `distilabel`\n",
    "\n",
    "The [`GenerateSentencePair`](https://distilabel.argilla.io/latest/components-gallery/tasks/generatesentencepair/) component from `distilabel` that can be used to generate training datasets for embeddings models. It is a pre-defined `Task` that given an `anchor` sentence generates a `positive` sentence related to the anchor. We will also generate unrelated `negative` sentences by passing `triplet=True` and we will also provide a `context` to guide the LLM towards more specific behavior. \n",
    "\n",
    "Additionally, we will use the [`OpenAILLM`](https://distilabel.argilla.io/latest/components-gallery/llms/openaillm/) with `gpt4o` and [`LoadDataFromHub`](https://distilabel.argilla.io/latest/components-gallery/steps/loaddatafromhub/) to load [our dataset](https://huggingface.co/datasets/zenml/rag_qa_embedding_questions_0_60_0).\n",
    "\n",
    "In our case, we will use the `page_content` column from our dataset as `anchor` to generate `positive` and `negatives` sentences that function as training data for the embedding model.\n",
    "\n",
    "Now, let's capture this logic in a `distilabel` `Pipeline`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from distilabel.steps.tasks import GenerateSentencePair\n",
    "from distilabel.llms import OpenAILLM\n",
    "from distilabel.steps import LoadDataFromHub\n",
    "from distilabel.pipeline import Pipeline\n",
    "\n",
    "# TODO: I think we might optimize this a bit more.\n",
    "\n",
    "context = (\n",
    "\"\"\"\n",
    "The text is a chunk from technical documentation of ZenML.\n",
    "ZenML is an MLOps + LLMOps framework that makes your infrastructure and workflow metadata accessible to data science teams.\n",
    "Along with prose explanations, the text chunk may include code snippets and logs but these are identifiable from the surrounding backticks.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = OpenAILLM(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "with Pipeline(name=\"generate_embedding_queries\") as pipeline:\n",
    "    load_dataset = LoadDataFromHub(\n",
    "        num_examples=10,  # uncomment this for demo purposes\n",
    "        output_mappings={\"page_content\": \"anchor\"},\n",
    "    )\n",
    "    generate_sentence_pair = GenerateSentencePair(\n",
    "        triplet=True,  # `False` to generate only positive\n",
    "        action=\"query\",\n",
    "        llm=llm,\n",
    "        input_batch_size=10,\n",
    "        context=context,\n",
    "    )\n",
    "\n",
    "    load_dataset >> generate_sentence_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can execute this using `pipeline.run`. We will provide some `parameters` to specific components within our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset = pipeline.run(  #\n",
    "    parameters={\n",
    "        load_dataset.name: {\n",
    "            \"repo_id\": \"zenml/rag_qa_embedding_questions_0_60_0\",\n",
    "            \"split\": \"train\",\n",
    "        },\n",
    "        generate_sentence_pair.name: {\n",
    "            \"llm\": {\n",
    "                \"generation_kwargs\": {\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_new_tokens\": 512,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vibe check our data again. If you are not happy with the results you can either tweak our `parameters` or optimize the `context` prompt which is passed to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "example = distiset[\"default\"][\"train\"][9]\n",
    "del example[\"embedding\"]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Push the distiset to the Hugging Face Hub\n",
    "\n",
    "Synthetic data generation can be expensive becuae of the reliance on LLMs, so first store our data on the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset.push_to_hub(\n",
    "    repo_id=\"zenml/rag_qa_embedding_questions_0_60_0\",\n",
    "    token=os.getenv(\"HUGGINGFACE_API_KEY\"),\n",
    "    create_pr=True, # TODO: why?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Review synthetic query generation with `argilla` \n",
    "\n",
    "Data is never as clean as it can be and this also holds for synthetically generated data, therefore, it is always good to spent some time and look at your data. We will used Argilla to do this. If you are not familiar with Argilla, we recommend taking a look at the [Argilla quickstar docs](https://docs.argilla.io/latest/getting_started/quickstart/). Alternatively, you can use your Hugging Face account to login to the [Argilla demo Space](https://argilla-argilla-template-space.hf.space).\n",
    "\n",
    "To start exploring data, we first need to define an `argilla.Dataset`. We will create a basic datset with some input `TextFields` for the `anchor` and output `TextQuestions` for the `positive` and `negative` pairs. Additionally, we will use the `parent_section` and `token_count` as `MetaDataProperty` and we will be adding some vectors to allow for semantic search. Finally, we will also compute current similarities for embeddings of `anchor-positive`, `positive-negative` and `anchor-negative` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"zenml/rag_qa_embedding_questions_0_60_0\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"  # Hugging Face model ID\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "\n",
    "settings = rg.Setting(\n",
    "    fields=[\n",
    "        rg.TextField(\"anchor\")\n",
    "    ],\n",
    "    questions=[\n",
    "        rg.TextQuestion(\"positive\"),\n",
    "        rg.TextQuestion(\"negative\")\n",
    "    ],\n",
    "    metadata=[\n",
    "        rg.TermsMetadataProperty(\"parent_section\"),\n",
    "        rg.IntegerMetadataProperty(\"token_count\"),\n",
    "        rg.FloatMetadataProperty(\"similarity-positive-negative\"),\n",
    "        rg.FloatMetadataProperty(\"similarity-anchor-positive\"),\n",
    "        rg.FloatMetadataProperty(\"similarity-anchor-negative\"),\n",
    "    ],\n",
    "    vectors=[\n",
    "        rg.VectorField(\"anchor-vector\", dimensions=model.get_sentence_embedding_dimension())\n",
    "    ]\n",
    ")\n",
    "ds = rg.Dataset(\n",
    "    name=\"rag_qa_embedding_questions_0_60_0\",\n",
    "    settings=settings\n",
    ")\n",
    "ds.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will process the original Hugging Face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def format_data(batch):\n",
    "    def get_embeddings(batch_column):\n",
    "        vectors = model.encode(batch_column)\n",
    "        return [vector.tolist() for vector in vectors]\n",
    "    batch[\"anchor-vector\"] = get_embeddings(batch[\"anchor\"])\n",
    "    batch[\"positive-vector\"] = get_embeddings(batch[\"positive\"])\n",
    "    batch[\"negative-vector\"] = get_embeddings(batch[\"negative\"])\n",
    "\n",
    "    def get_similarities(a, b):\n",
    "        similarities = []\n",
    "        \n",
    "        for pos_vec, neg_vec in zip(a, b):\n",
    "            similarity = cosine_similarity([pos_vec], [neg_vec])[0][0]\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    batch[\"similarity-positive-negative\"] = get_similarities(batch[\"positive-vector\"], batch[\"negative-vector\"])\n",
    "    batch[\"similarity-anchor-positive\"] = get_similarities(batch[\"anchor-vector\"], batch[\"positive-vector\"])\n",
    "    batch[\"similarity-anchor-negative\"] = get_similarities(batch[\"anchor-vector\"], batch[\"negative-vector\"])\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(format_data, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will log the records to Argilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for idx, entry in enumerate(dataset):\n",
    "    records.append(\n",
    "        rg.Record(\n",
    "            id=idx,\n",
    "            fields={\"achor\": entry[\"anchor\"]},\n",
    "            suggestions=[\n",
    "                rg.Suggestion(\"positive\", value=entry[\"positive\"]),\n",
    "                rg.Suggestion(\"negative\", value=entry[\"negative\"]),\n",
    "            ],\n",
    "            metadata={\n",
    "                \"parent_section\": entry[\"parent_section\"],\n",
    "                \"token_count\": entry[\"token_count\"],\n",
    "                \"similarity-positive-negative\": entry[\"similarity-positive-negative\"],\n",
    "                \"similarity-anchor-positive\": entry[\"similarity-anchor-positive\"],\n",
    "                \"similarity-anchor-negative\": entry[\"similarity-anchor-negative\"]\n",
    "            },\n",
    "            vectors={\"question-vector\": entry[\"question-vector\"]}\n",
    "        )\n",
    "    )\n",
    "ds.records.log(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore the UI and filter out the bad apples. Tip, start filtering on high similarity of 'similarity-anchor-negative' or 'similarity-positive-negative' and low similarity of 'similarity-anchor-positive'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the embedding dataset\n",
    "\n",
    "Follows [Phil Schmid's tutorial](https://www.philschmid.de/fine-tune-embedding-model-for-rag#5-evaluate-fine-tuned-model-against-baseline) fairly heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9cbf2611bf434780650dcd54817c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efcb3315ae24e61a0aa59a521430f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1395773"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"zenml/rag_qa_embedding_questions_0_60_0\", split=\"train\")\n",
    "\n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    "\n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset_path = \"../data/train_dataset.json\"\n",
    "test_dataset_path = \"../data/test_dataset.json\"\n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(train_dataset_path, orient=\"records\")\n",
    "dataset[\"test\"].to_json(test_dataset_path, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create baseline + evaluate pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca2a1a5d3ce47b0929267966d6de25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f38254457d046228c32052ae15ebbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [384, 256, 128, 64]  # Important: large to small\n",
    "\n",
    "# Load a model\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# load test dataset\n",
    "test_dataset = load_dataset(\"json\", data_files=test_dataset_path, split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=train_dataset_path, split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "\n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    "\n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    "\n",
    "\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_384_cosine_ndcg@10: 0.5163534966981647\n",
      "dim_256_cosine_ndcg@10: 0.5007072121406431\n",
      "dim_128_cosine_ndcg@10: 0.47107077962798377\n",
      "dim_64_cosine_ndcg@10: 0.40703812333002265\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    "\n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    "\n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    model_kwargs={\"attn_implementation\": \"sdpa\"},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"BGE base Financial Matryoshka\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "matryoshka_dimensions = [384, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (pyOpenSSL 24.1.0 (/home/strickvl/.pyenv/versions/3.10.12/envs/new-rag/lib/python3.10/site-packages), Requirement.parse('pyopenssl<24.0.0')).\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# load train dataset again\n",
    "train_dataset = load_dataset(\"json\", data_files=train_dataset_path, split=\"train\")\n",
    "\n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"bge-base-financial-matryoshka\",  # output directory and hugging face model ID\n",
    "    num_train_epochs=4,  # number of epochs\n",
    "    per_device_train_batch_size=32,  # train batch size\n",
    "    gradient_accumulation_steps=16,  # for a global batch size of 512\n",
    "    per_device_eval_batch_size=16,  # evaluation batch size\n",
    "    warmup_ratio=0.1,  # warmup ratio\n",
    "    learning_rate=2e-5,  # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",  # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",  # use fused adamw optimizer\n",
    "    tf32=True,  # use tf32 precision\n",
    "    bf16=True,  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",  # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",  # save after each epoch\n",
    "    logging_steps=10,  # log every 10 steps\n",
    "    save_total_limit=3,  # save only the last 3 models\n",
    "    load_best_model_at_end=True,  # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"positive\", \"anchor\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstrickvl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/strickvl/coding/zenml-projects/llm-complete-guide/notebooks/wandb/run-20240626_183555-5l8ld8n7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/strickvl/sentence-transformers/runs/5l8ld8n7' target=\"_blank\">bge-base-financial-matryoshka</a></strong> to <a href='https://wandb.ai/strickvl/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/strickvl/sentence-transformers' target=\"_blank\">https://wandb.ai/strickvl/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/strickvl/sentence-transformers/runs/5l8ld8n7' target=\"_blank\">https://wandb.ai/strickvl/sentence-transformers/runs/5l8ld8n7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:10, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 384 Cosine Accuracy@1</th>\n",
       "      <th>Dim 384 Cosine Accuracy@3</th>\n",
       "      <th>Dim 384 Cosine Accuracy@5</th>\n",
       "      <th>Dim 384 Cosine Accuracy@10</th>\n",
       "      <th>Dim 384 Cosine Precision@1</th>\n",
       "      <th>Dim 384 Cosine Precision@3</th>\n",
       "      <th>Dim 384 Cosine Precision@5</th>\n",
       "      <th>Dim 384 Cosine Precision@10</th>\n",
       "      <th>Dim 384 Cosine Recall@1</th>\n",
       "      <th>Dim 384 Cosine Recall@3</th>\n",
       "      <th>Dim 384 Cosine Recall@5</th>\n",
       "      <th>Dim 384 Cosine Recall@10</th>\n",
       "      <th>Dim 384 Cosine Ndcg@10</th>\n",
       "      <th>Dim 384 Cosine Mrr@10</th>\n",
       "      <th>Dim 384 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.072892</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.515565</td>\n",
       "      <td>0.448738</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.176707</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.500707</td>\n",
       "      <td>0.437545</td>\n",
       "      <td>0.447064</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.158635</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.472812</td>\n",
       "      <td>0.413843</td>\n",
       "      <td>0.422149</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.140562</td>\n",
       "      <td>0.095181</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.407038</td>\n",
       "      <td>0.349493</td>\n",
       "      <td>0.358603</td>\n",
       "      <td>0.358603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.198795</td>\n",
       "      <td>0.137349</td>\n",
       "      <td>0.076506</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.568495</td>\n",
       "      <td>0.505474</td>\n",
       "      <td>0.512137</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.137349</td>\n",
       "      <td>0.076506</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.489604</td>\n",
       "      <td>0.496523</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.536145</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.178715</td>\n",
       "      <td>0.122892</td>\n",
       "      <td>0.073494</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.536145</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.518131</td>\n",
       "      <td>0.449969</td>\n",
       "      <td>0.457559</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.160643</td>\n",
       "      <td>0.114458</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.475449</td>\n",
       "      <td>0.416375</td>\n",
       "      <td>0.425072</td>\n",
       "      <td>0.425072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@3:\n",
      "0.5421686746987951\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@5:\n",
      "0.6024096385542169\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@10:\n",
      "0.7289156626506024\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@3:\n",
      "0.18072289156626506\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@5:\n",
      "0.12048192771084336\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@10:\n",
      "0.07289156626506023\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@3:\n",
      "0.5421686746987951\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@5:\n",
      "0.6024096385542169\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@10:\n",
      "0.7289156626506024\n",
      "Attempted to log scalar metric eval_dim_384_cosine_ndcg@10:\n",
      "0.515564763242915\n",
      "Attempted to log scalar metric eval_dim_384_cosine_mrr@10:\n",
      "0.44873780837636285\n",
      "Attempted to log scalar metric eval_dim_384_cosine_map@100:\n",
      "0.4562356258627585\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@3:\n",
      "0.5301204819277109\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@5:\n",
      "0.6024096385542169\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@10:\n",
      "0.6987951807228916\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@3:\n",
      "0.17670682730923695\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@5:\n",
      "0.12048192771084336\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@10:\n",
      "0.06987951807228915\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@3:\n",
      "0.5301204819277109\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@5:\n",
      "0.6024096385542169\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@10:\n",
      "0.6987951807228916\n",
      "Attempted to log scalar metric eval_dim_256_cosine_ndcg@10:\n",
      "0.5007072121406431\n",
      "Attempted to log scalar metric eval_dim_256_cosine_mrr@10:\n",
      "0.43754541977433564\n",
      "Attempted to log scalar metric eval_dim_256_cosine_map@100:\n",
      "0.4470640633893574\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@3:\n",
      "0.4759036144578313\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@5:\n",
      "0.5481927710843374\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@10:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@3:\n",
      "0.15863453815261044\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@5:\n",
      "0.10963855421686744\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@10:\n",
      "0.06626506024096385\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@3:\n",
      "0.4759036144578313\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@5:\n",
      "0.5481927710843374\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@10:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_128_cosine_ndcg@10:\n",
      "0.4728121340033927\n",
      "Attempted to log scalar metric eval_dim_128_cosine_mrr@10:\n",
      "0.41384346911455355\n",
      "Attempted to log scalar metric eval_dim_128_cosine_map@100:\n",
      "0.4221487300454246\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@1:\n",
      "0.24096385542168675\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@3:\n",
      "0.42168674698795183\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@5:\n",
      "0.4759036144578313\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@10:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@1:\n",
      "0.24096385542168675\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@3:\n",
      "0.14056224899598393\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@5:\n",
      "0.09518072289156627\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@10:\n",
      "0.059036144578313236\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@1:\n",
      "0.24096385542168675\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@3:\n",
      "0.42168674698795183\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@5:\n",
      "0.4759036144578313\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@10:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_64_cosine_ndcg@10:\n",
      "0.40703812333002265\n",
      "Attempted to log scalar metric eval_dim_64_cosine_mrr@10:\n",
      "0.34949321093899416\n",
      "Attempted to log scalar metric eval_dim_64_cosine_map@100:\n",
      "0.35860295559789424\n",
      "Attempted to log scalar metric eval_sequential_score:\n",
      "0.35860295559789424\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "1.095\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c079df06e2c4fac909b82725d1d19c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@3:\n",
      "0.5963855421686747\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@5:\n",
      "0.6807228915662651\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@3:\n",
      "0.19879518072289157\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@5:\n",
      "0.13614457831325297\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@10:\n",
      "0.07650602409638552\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@3:\n",
      "0.5963855421686747\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@5:\n",
      "0.6807228915662651\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_384_cosine_ndcg@10:\n",
      "0.5653480781338897\n",
      "Attempted to log scalar metric eval_dim_384_cosine_mrr@10:\n",
      "0.5016255498183211\n",
      "Attempted to log scalar metric eval_dim_384_cosine_map@100:\n",
      "0.5080883205221587\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@3:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@5:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@10:\n",
      "0.7590361445783133\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@3:\n",
      "0.1967871485943775\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@5:\n",
      "0.1325301204819277\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@10:\n",
      "0.07590361445783131\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@3:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@5:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@10:\n",
      "0.7590361445783133\n",
      "Attempted to log scalar metric eval_dim_256_cosine_ndcg@10:\n",
      "0.5530555143661541\n",
      "Attempted to log scalar metric eval_dim_256_cosine_mrr@10:\n",
      "0.48680914132721387\n",
      "Attempted to log scalar metric eval_dim_256_cosine_map@100:\n",
      "0.4937772314167388\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@3:\n",
      "0.5240963855421686\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@5:\n",
      "0.6144578313253012\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@10:\n",
      "0.7289156626506024\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@3:\n",
      "0.1746987951807229\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@5:\n",
      "0.12289156626506023\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@10:\n",
      "0.07289156626506023\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@3:\n",
      "0.5240963855421686\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@5:\n",
      "0.6144578313253012\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@10:\n",
      "0.7289156626506024\n",
      "Attempted to log scalar metric eval_dim_128_cosine_ndcg@10:\n",
      "0.5140975530326504\n",
      "Attempted to log scalar metric eval_dim_128_cosine_mrr@10:\n",
      "0.44663893669917765\n",
      "Attempted to log scalar metric eval_dim_128_cosine_map@100:\n",
      "0.4541934922020714\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@3:\n",
      "0.463855421686747\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@5:\n",
      "0.5662650602409639\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@10:\n",
      "0.6566265060240963\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@3:\n",
      "0.1546184738955823\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@5:\n",
      "0.11325301204819276\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@10:\n",
      "0.06566265060240963\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@1:\n",
      "0.30120481927710846\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@3:\n",
      "0.463855421686747\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@5:\n",
      "0.5662650602409639\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@10:\n",
      "0.6566265060240963\n",
      "Attempted to log scalar metric eval_dim_64_cosine_ndcg@10:\n",
      "0.46883509708072285\n",
      "Attempted to log scalar metric eval_dim_64_cosine_mrr@10:\n",
      "0.4095979154714095\n",
      "Attempted to log scalar metric eval_dim_64_cosine_map@100:\n",
      "0.4182697872360409\n",
      "Attempted to log scalar metric eval_sequential_score:\n",
      "0.4182697872360409\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "1.092\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric epoch:\n",
      "2.0\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@3:\n",
      "0.5963855421686747\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@5:\n",
      "0.6867469879518072\n",
      "Attempted to log scalar metric eval_dim_384_cosine_accuracy@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@3:\n",
      "0.19879518072289157\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@5:\n",
      "0.13734939759036144\n",
      "Attempted to log scalar metric eval_dim_384_cosine_precision@10:\n",
      "0.07650602409638552\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@1:\n",
      "0.3795180722891566\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@3:\n",
      "0.5963855421686747\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@5:\n",
      "0.6867469879518072\n",
      "Attempted to log scalar metric eval_dim_384_cosine_recall@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_384_cosine_ndcg@10:\n",
      "0.5684952818876474\n",
      "Attempted to log scalar metric eval_dim_384_cosine_mrr@10:\n",
      "0.5054742780646396\n",
      "Attempted to log scalar metric eval_dim_384_cosine_map@100:\n",
      "0.5121372675104298\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@3:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@5:\n",
      "0.6867469879518072\n",
      "Attempted to log scalar metric eval_dim_256_cosine_accuracy@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@3:\n",
      "0.1967871485943775\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@5:\n",
      "0.13734939759036144\n",
      "Attempted to log scalar metric eval_dim_256_cosine_precision@10:\n",
      "0.07650602409638552\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@1:\n",
      "0.3433734939759036\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@3:\n",
      "0.5903614457831325\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@5:\n",
      "0.6867469879518072\n",
      "Attempted to log scalar metric eval_dim_256_cosine_recall@10:\n",
      "0.7650602409638554\n",
      "Attempted to log scalar metric eval_dim_256_cosine_ndcg@10:\n",
      "0.5566750064887807\n",
      "Attempted to log scalar metric eval_dim_256_cosine_mrr@10:\n",
      "0.48960365270606254\n",
      "Attempted to log scalar metric eval_dim_256_cosine_map@100:\n",
      "0.4965227953230801\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@3:\n",
      "0.536144578313253\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@5:\n",
      "0.6144578313253012\n",
      "Attempted to log scalar metric eval_dim_128_cosine_accuracy@10:\n",
      "0.7349397590361446\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@3:\n",
      "0.17871485943775098\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@5:\n",
      "0.12289156626506023\n",
      "Attempted to log scalar metric eval_dim_128_cosine_precision@10:\n",
      "0.07349397590361444\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@1:\n",
      "0.3253012048192771\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@3:\n",
      "0.536144578313253\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@5:\n",
      "0.6144578313253012\n",
      "Attempted to log scalar metric eval_dim_128_cosine_recall@10:\n",
      "0.7349397590361446\n",
      "Attempted to log scalar metric eval_dim_128_cosine_ndcg@10:\n",
      "0.5181307756477362\n",
      "Attempted to log scalar metric eval_dim_128_cosine_mrr@10:\n",
      "0.44996892331229676\n",
      "Attempted to log scalar metric eval_dim_128_cosine_map@100:\n",
      "0.4575590763015045\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@3:\n",
      "0.4819277108433735\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@5:\n",
      "0.572289156626506\n",
      "Attempted to log scalar metric eval_dim_64_cosine_accuracy@10:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@3:\n",
      "0.1606425702811245\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@5:\n",
      "0.1144578313253012\n",
      "Attempted to log scalar metric eval_dim_64_cosine_precision@10:\n",
      "0.06626506024096383\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@1:\n",
      "0.3072289156626506\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@3:\n",
      "0.4819277108433735\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@5:\n",
      "0.572289156626506\n",
      "Attempted to log scalar metric eval_dim_64_cosine_recall@10:\n",
      "0.6626506024096386\n",
      "Attempted to log scalar metric eval_dim_64_cosine_ndcg@10:\n",
      "0.47544898005380076\n",
      "Attempted to log scalar metric eval_dim_64_cosine_mrr@10:\n",
      "0.4163750239051445\n",
      "Attempted to log scalar metric eval_dim_64_cosine_map@100:\n",
      "0.4250718337468105\n",
      "Attempted to log scalar metric eval_sequential_score:\n",
      "0.4250718337468105\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "1.0923\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.0\n",
      "Attempted to log scalar metric epoch:\n",
      "2.6666666666666665\n",
      "Attempted to log scalar metric train_runtime:\n",
      "13.9911\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "425.985\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "0.286\n",
      "Attempted to log scalar metric total_flos:\n",
      "0.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "4.075438499450684\n",
      "Attempted to log scalar metric epoch:\n",
      "2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# save the best model\n",
    "trainer.save_model()\n",
    "\n",
    "# push model to hub\n",
    "# trainer.model.push_to_hub(\"bge-base-financial-matryoshka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate fine-tuned model against baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_384_cosine_ndcg@10: 0.5684952818876474\n",
      "dim_256_cosine_ndcg@10: 0.5566750064887807\n",
      "dim_128_cosine_ndcg@10: 0.5181307756477362\n",
      "dim_64_cosine_ndcg@10: 0.47544898005380076\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    "\n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    "\n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
