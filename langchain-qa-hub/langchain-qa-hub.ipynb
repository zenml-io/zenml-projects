{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstart your ZenML Projects with the ZenML Hub\n",
    "\n",
    "The ZenML Hub is the central location for users to search, discover, and share ZenML integrations, third-party plugins, and community-contributed code. It serves as a repository of pre-built pipelines, steps, materializers, stack components, and more, allowing users to quickly implement standard use cases and build better models faster.\n",
    "\n",
    "In this example, we will use the `langchain_qa_example` plugin, available on the ZenML Hub, which demonstrates how to build a question-answering MLOps pipeline using Langchain, LlamaIndex, and OpenAI. The plugin provides a simple pipeline and steps that fetch data from various sources, create an index, and answer queries across the corpus using a GPT-3.5 (and beyond) LLM powered by OpenAI.\n",
    "\n",
    "To get started, let's install and initialize ZenML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zenml\n",
    "!zenml init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out about all plugins that are currently available in the ZenML Hub, you can\n",
    "browse the `Plugins` section of the ZenML dashboard\n",
    "\n",
    "![Dashboard Plugins Page](./assets/plugin_list_dashboard.png)\n",
    "\n",
    "Alternatively, you can use the `zenml hub list` CLI command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml hub list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zenml hub list output](./assets/plugin_list_cli.png)\n",
    "\n",
    "As we see, there are a lot of plugins available in the ZenML Hub that we can\n",
    "use to kickstart our projects. In this example, we will use the \n",
    "`langchain_qa_example` plugin to build a pipeline that can answer \n",
    "questions about the ZenML documentation.\n",
    "\n",
    "Before installing the plugin, let's briefly check out the \n",
    "[plugin source code](https://github.com/zenml-io/zenml-hub-plugins/tree/main/src/langchain_zenml_qa_example) \n",
    "to find out what it contains. Alternatively, If you prefer to inspect the code \n",
    "in your local code editor, you can also pull the source code to your local\n",
    "machine using the `zenml hub clone` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml hub clone langchain_qa_example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the plugin contains several steps, a pipeline, as well as a\n",
    "`build_zenml_docs_qa_pipeline` utility function:\n",
    "\n",
    "```python\n",
    "from .pipelines import qa_pipeline, build_zenml_docs_qa_pipeline\n",
    "from .steps import (\n",
    "    docs_loader_step,\n",
    "    DocsLoaderParameters,\n",
    "    index_generator_step,\n",
    "    slack_loader_step,\n",
    "    SlackLoaderParameters,\n",
    "    web_url_loader_step,\n",
    "    WebUrlLoaderParameters,\n",
    "    question_answerer_step,\n",
    "    QAParameters,\n",
    ")\n",
    "```\n",
    "\n",
    "Let's now install this plugin and ask it questions about ZenML!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml hub install langchain_qa_example -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask ZenML Questions to GPT\n",
    "\n",
    "Using the ZenML Hub, we can very easily leverage the GPT-3.5 language model for \n",
    "answering questions related to ZenML documentation. All we need to do is set\n",
    "the `OPENAI_API_KEY` environment variable and call and run the\n",
    "`build_zenml_docs_qa_pipeline` function from the `langchain_qa_example` plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# TODO: You need to set your OpenAI API key below to access GPT-3.5.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.hub.langchain_qa_example import build_zenml_docs_qa_pipeline\n",
    "\n",
    "\n",
    "pipeline = build_zenml_docs_qa_pipeline(question=\"What is ZenML?\", load_all_paths=False).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Your Own Docs\n",
    "\n",
    "One of the key features of the ZenML Hub is the ability to easily customize and extend pre-built pipelines and steps to suit specific use cases. In this case, we can recreate the `qa_pipeline` and pass a custom `docs_uri` to the `docs_loader_step` to specify a custom documentation URL, allowing us to ask questions about any docs page we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.hub.langchain_qa_example import docs_loader_step, index_generator_step, question_answerer_step, qa_pipeline, DocsLoaderParameters, QAParameters\n",
    "\n",
    "qa_pipeline(\n",
    "    document_loader=docs_loader_step(DocsLoaderParameters(docs_uri=\"https://docs.zenml.io\")),\n",
    "    index_generator=index_generator_step(),\n",
    "    question_answerer=question_answerer_step(\n",
    "        QAParameters(question=\"What is ZenML?\")\n",
    "    ),\n",
    ").run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Different Data Source\n",
    "\n",
    "Let us now explore how to use a different data source in the QA pipeline. The `langchain_qa_example` plugin also\n",
    "contains another `web_url_loader_step` that we can use to load data from an arbitrary webpage, which we will use below.\n",
    "Alternatively, we could also use any other langchain-compatible data loading step here. See, for instance, the \n",
    "[langchain_loader_steps plugin](https://github.com/zenml-io/zenml-hub-plugins/tree/main/src/langchain_loader_steps)\n",
    "or the\n",
    "[llama_index_loader_steps](https://github.com/zenml-io/zenml-hub-plugins/tree/main/src/langchain_loader_steps)\n",
    "plugins for some inspirations.\n",
    "By leveraging the power of the ZenML Hub, we can easily adapt our ML pipeline to work with a wide range of data sources, making our workflow more versatile and effective in solving real-world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.hub.langchain_qa_example import web_url_loader_step, WebUrlLoaderParameters\n",
    "\n",
    "qa_pipeline(\n",
    "    document_loader=web_url_loader_step(WebUrlLoaderParameters(urls=[\"https://zenml.io/integrations/\"])),\n",
    "    index_generator=index_generator_step(),\n",
    "    question_answerer=question_answerer_step(\n",
    "        QAParameters(question=\"Name five tools that ZenML integrates with.\")\n",
    "    ),\n",
    ").run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Your Own Plugin\n",
    "\n",
    "The ZenML Hub is open for community contributions and anyone with a GitHub\n",
    "account can submit plugins. To find out how, check out the\n",
    "[ZenML Hub Plugin Template](https://github.com/zenml-io/zenml-hub-plugin-template).\n",
    "\n",
    "If you would like to learn more about the ZenML Hub in general, check out the\n",
    "[ZenML Hub Documentation](https://docs.zenml.io/user-guide/advanced-guide/environment-management/use-the-hub) or the [ZenML Hub Launch Blog Post](https://blog.zenml.io/zenml-hub-launch)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenmllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
