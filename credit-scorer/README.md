# Credit Scoring EU AI Act Demo

Automatically generate complete EU AI Act compliance documentation with minimal manual effort for credit scoring models.

<div align="center"> <img src="assets/compliance-dashboard.png" alt="Compliance Dashboard" width="800" /> </div>

## ğŸ¯ Regulatory Context

Financial institutions must comply with the EU AI Act for any highâ€‘risk AI system. Meeting Articles 9â€“18 requires extensive documentation and auditing. This pipeline delivers a productionâ€‘ready workflow that:

- Generates all required technical evidence automatically
- Ensures robust risk management and human oversight
- Maintains full audit trails with versioned artifacts
- Provides realâ€‘time compliance dashboards for stakeholders

## ğŸ” Data Overview

This project uses a credit scoring dataset based on the Home Credit Default Risk data. The raw dataset contains potentially sensitive attributes such as `CODE_GENDER`, `DAYS_BIRTH`, `NAME_EDUCATION_TYPE`, `NAME_FAMILY_STATUS`, and `NAME_HOUSING_TYPE`, which can be filtered using the pipeline's `sensitive_attributes` parameter to comply with fairness requirements.

Key fields used for modeling:

| Field              | Description                                     |
| ------------------ | ----------------------------------------------- |
| `AMT_INCOME_TOTAL` | Annual income of the applicant                  |
| `AMT_CREDIT`       | Credit amount of the loan                       |
| `AMT_ANNUITY`      | Loan annuity amount                             |
| `EXT_SOURCE_1/2/3` | External source scores (credit history proxies) |
| `TARGET`           | Default indicator (0 = no default, 1 = default) |

Automated preprocessing handles:

- Missing value imputation using SimpleImputer
- Feature scaling with StandardScaler (optional)
- Categorical encoding with OneHotEncoder
- Feature engineering including age derivation from `DAYS_BIRTH`

## ğŸš€ Pipeline Architecture

<div> <img src="assets/e2e.png" alt="End-to-End Architecture" width="1200" /> </div>

The system implements three main pipelines that map directly to EU AI Act requirements:

| Pipeline                                                        | Key Steps                                                                                                                                                  | EU AI Act Focus |
| --------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------- |
| **[Feature Engineering](src/pipelines/feature_engineering.py)** | **Ingest** â†’ Record SHAâ€‘256 provenance ğŸ“¥<br>**Profile** â†’ WhyLogs data governance ğŸ“Š<br>**Preprocess** â†’ Impute, encode, normalize ğŸ”§                     | Arts 10, 12, 15 |
| **[Training](src/pipelines/training.py)**                       | **Train** â†’ LightGBM w/ classâ€‘imbalance handling ğŸ¯<br>**Evaluate** â†’ Accuracy, AUC, fairness analysis âš–ï¸<br>**Assess** â†’ Risk scoring & model registry ğŸ“‹ | Arts 9, 11, 15  |
| **[Deployment](src/pipelines/deployment.py)**                   | **Approve** â†’ Human oversight gate ğŸ™‹â€â™‚ï¸<br>**Deploy** â†’ Modal API deployment ğŸš€<br>**Monitor** â†’ SBOM + postâ€‘market tracking ğŸ“ˆ                              | Arts 14, 17, 18 |

Each pipeline run automatically versions all inputs/outputs, generates profiling reports, creates risk assessments, produces SBOM, and compiles complete Annex IV technical documentation.

## ğŸ› ï¸ Project Structure

```
credit-scorer/
â”‚
â”œâ”€â”€ run.py                  # Main pipeline execution script
â”œâ”€â”€ run_dashboard.py        # Dashboard launcher
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/               # Dataset directory
â”‚   â”œâ”€â”€ pipelines/          # Pipeline definitions
â”‚   â”œâ”€â”€ steps/              # Pipeline step implementations
â”‚   â”œâ”€â”€ configs/            # Configuration files
â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â””â”€â”€ constants/          # Project constants
â”‚
â”œâ”€â”€ streamlit_app/          # Compliance dashboard
â”œâ”€â”€ modal_app/              # Modal deployment code
â”œâ”€â”€ docs/                   # Documentation and compliance artifacts
â”œâ”€â”€ models/                 # Saved model artifacts
â”œâ”€â”€ assets/                 # Images and static resources
â””â”€â”€ scripts/                # Helper scripts
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.12+
- ZenML >= 0.82.1
- Modal account (for deployment pipeline)
- WhyLogs integration (for data profiling)

### Installation & Configuration

1. Install dependencies

```bash
pip install -r requirements.txt
```

2. Set up ZenML

```bash
zenml init
```

3. Install [WhyLogs integration](https://docs.zenml.io/stacks/stack-components/data-validators/whylogs):

```bash
zenml integration install whylogs -y
zenml data-validator register whylogs_data_validator --flavor=whylogs
zenml stack update <STACK_NAME> -dv whylogs_data_validator
```

## ğŸ“Š Running Pipelines

### Basic Commands

```bash
# Run individual pipelines
python run.py --feature    # Feature engineering (Articles 10, 12)
python run.py --train      # Model training (Articles 9, 11, 15)
python run.py --deploy     # Deployment (Articles 14, 17, 18)

# Pipeline options
python run.py --train --auto-approve     # Skip manual approval steps
python run.py --feature --no-cache       # Disable ZenML caching
python run.py --deploy --config-dir ./my-configs  # Custom config directory
```

### View Compliance Dashboard

The project includes a Streamlit-based compliance dashboard that provides:

- Real-time visibility into EU AI Act compliance status
- Executive summary of current risk levels and compliance metrics
- Generated Annex IV documentation with export options

To run the dashboard:

```bash
# Launch the Streamlit compliance dashboard
python run_dashboard.py
```

> **Note:** All compliance artifacts are also directly accessible through the ZenML dashboard. The Streamlit dashboard is provided as a convenient additional interface for browsing compliance information interactively.

### ğŸ”§ Configuration

Pipeline configurations are stored in `src/configs/`:

- `feature_engineering.yaml` - Data processing and profiling settings
- `training.yaml` - Model training and evaluation parameters
- `deployment.yaml` - Deployment and monitoring configuration

### â˜ï¸ Cloud Deployment

You can store artifacts and run pipelines locally, but storing them in the cloud enables you to [visualize the data artifacts produced by pipelines](https://docs.zenml.io/concepts/artifacts/visualizations) directly in the ZenML dashboard.

See the [Cloud Deployment Guide](docs/guides/cloud_deployment.md) for step-by-step instructions on setting up a cloud artifact store and orchestrator.

### ğŸ“„ Generated Artifacts

Each pipeline run creates a unique release directory in `docs/releases/<run_id>/` containing all compliance artifacts. Here are some guides to help you navigate the artifacts produced and what ZenML features were leveraged to produce them:

- [Data Sources](docs/guides/compliance_data_sources.md)
- [Pipeline Steps â†’ Articles](docs/guides/pipeline_to_articles.md)
- [Article Coverage Matrix](docs/guides/interdependencies.md)
- [ZenML Feature Mapping](docs/guides/zenml_eu_act_features.md)

## ğŸ“š Documentation

- **[ZenML Documentation](https://docs.zenml.io/)**
- **[EU AI Act Compliance Traceability](docs/guides/compliance_traceability.md)**
- **[QMS Templates](docs/templates/qms/)** - Quality management system documentation templates

**Note**: This project provides the technical evidence required by the EU AI Act. For complete compliance, organizations must also maintain formal quality management documentation and processes.

### Additional Resources

- [EU AI Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)
- [WhyLogs Documentation](https://whylogs.readthedocs.io/en/latest/index.html)
- [Modal Documentation](https://modal.com/docs)

## ğŸ“„ License

This project is licensed under the Apache License 2.0.
