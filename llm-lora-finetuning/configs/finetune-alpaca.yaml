model:
  name: llm_lora-Mistral-7B-Instruct-v0.1
  description: "Fine-tune `mistralai/Mistral-7B-Instruct-v0.1`."
  tags:
    - llm
    - lora
    - mistralai/Mistral-7B-Instruct-v0.1
    - alpaca

settings:
  docker:
    parent_image: pytorch/pytorch:2.2.0-cuda11.8-cudnn8-runtime

steps:
  finetune:
    # Uncomment and set value to use a step operator for this step
    # step_operator:
    enable_step_logs: False
    parameters:
      config:
        base_model_repo: mistralai/Mistral-7B-Instruct-v0.1
        from_safetensors: False
        precision: bf16-true
        quantize: bnb.nf4 # Enable quantization with 4-bit normal float
        # OPTIONAL: Configure Huggingface repository to which the merged model should be pushed
        # merged_output_repo:
        # OPTIONAL: Configure Huggingface repository to which the adapter should be pushed
        # adapter_output_repo:
        training:
          save_interval: 1
          epochs: 5
          epoch_size: 50000
          global_batch_size: 128
          micro_batch_size: 4
          learning_rate: 3e-4
