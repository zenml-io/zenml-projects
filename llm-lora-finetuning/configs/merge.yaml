model:
  name: llm_lora-Mistral-7B-Instruct-v0.1
  description: "Fine-tune `mistralai/Mistral-7B-Instruct-v0.1`."
  tags:
    - llm
    - lora
    - mistralai/Mistral-7B-Instruct-v0.1

steps:
  merge:
    parameters:
      config:
        base_model_repo: mistralai/Mistral-7B-Instruct-v0.1
        from_safetensors: False
        # REQUIRED: Huggingface repository in which to adapter is stored
        adapter_repo: null
        # REQUIRED: Huggingface repository to which the merged model should be pushed
        output_repo: null
        precision: bf16-true